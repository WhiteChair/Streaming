{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Data preprocessing</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SQLContext\n",
    "\n",
    "sqlContext = SQLContext(sc)\n",
    "data = sqlContext.read.format('com.databricks.spark.csv').options(header='true', \n",
    "                                                                  inferschema='true', \n",
    "                                                                  quote = '\"', \n",
    "                                                                  escape = '\"',\n",
    "                                                                 multiline = 'true',\n",
    "                                                                 ignoreTrailingWhiteSpace = 'true').load('Data\\\\data.csv')\n",
    "\n",
    "# There were some problems reading the data, here I found the solutions\n",
    "# https://stackoverflow.com/questions/40413526/reading-csv-files-with-quoted-fields-containing-embedded-commas\n",
    "#https://stackoverflow.com/questions/50477857/spark-fails-to-read-csv-when-last-column-name-contains-spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+--------------------+--------------+----------+--------------+----------+--------------------+------------+\n",
      "|  X|          book_title|        review_title|   review_user|   book_id|     review_id| timestamp|         review_text|review_score|\n",
      "+---+--------------------+--------------------+--------------+----------+--------------+----------+--------------------+------------+\n",
      "|  1|A Gentleman in Mo...|Russian aristocra...|    Kansabelle|0143110438|R2UFCQ9WES7VFH|1555241537|A great read. In ...|           4|\n",
      "|  2|A Gentleman in Mo...|Knowing nothing a...|  D.P. McHenry|0143110438|R24B1HA9J9I99G|1555241542|Great story, well...|           4|\n",
      "|  3|Pet Sematary: A N...|One of King's fin...|Gordon Hoffman|198211598X|R1P137WFADSBYR|1555241649|Only the second n...|           4|\n",
      "|  4|Less (Winner of t...|     Not my favorite|     R. Zocher|0316316121|R35533AKR5CBNS|1555242044|This book is t wh...|           4|\n",
      "|  5|         Supermarket|      AMAZING, BOBBY|    D. Mahoney|1982127139|R1D6LXSDR0CRMN|1555242169|As someone who ha...|           4|\n",
      "+---+--------------------+--------------------+--------------+----------+--------------+----------+--------------------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#drop_list = ['Dates', 'DayOfWeek', 'PdDistrict', 'Resolution', 'Address', 'X', 'Y']\n",
    "#data = data.select([column for column in data.columns if column not in drop_list])\n",
    "data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- X: integer (nullable = true)\n",
      " |-- book_title: string (nullable = true)\n",
      " |-- review_title: string (nullable = true)\n",
      " |-- review_user: string (nullable = true)\n",
      " |-- book_id: string (nullable = true)\n",
      " |-- review_id: string (nullable = true)\n",
      " |-- timestamp: integer (nullable = true)\n",
      " |-- review_text: string (nullable = true)\n",
      " |-- review_score: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----+\n",
      "|review_score|count|\n",
      "+------------+-----+\n",
      "|           5| 3236|\n",
      "|           4|  598|\n",
      "|           3|  187|\n",
      "|           1|  110|\n",
      "|           2|  108|\n",
      "+------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "data.groupBy(\"review_score\") \\\n",
    "    .count() \\\n",
    "    .orderBy(col(\"count\").desc()) \\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4239"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------------+--------------------+-----------+----------+--------------+----------+-----------+------------+\n",
      "|   X|          book_title|        review_title|review_user|   book_id|     review_id| timestamp|review_text|review_score|\n",
      "+----+--------------------+--------------------+-----------+----------+--------------+----------+-----------+------------+\n",
      "|1121|Lies My Doctor To...|This book gave a ...|   mawshell|162860378X|R3SIH2LVO3EYMH|1555252626|       null|           5|\n",
      "+----+--------------------+--------------------+-----------+----------+--------------+----------+-----------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#data.filter(\"review_score is NULL\").show() # No nulls anymore\n",
    "#data.filter(\"X is NULL\").show() \n",
    "#data.filter(\"book_title is NULL\").show()\n",
    "#data.filter(\"review_title is NULL\").show()\n",
    "#data.filter(\"review_user is NULL\").show()\n",
    "#data.filter(\"book_id is NULL\").show()\n",
    "#data.filter(\"review_id is NULL\").show()\n",
    "#data.filter(\"timestamp is NULL\").show()\n",
    "data.filter(\"review_text is NULL\").show() # There is one null\n",
    "#data.filter(\"review_score is NULL\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove observation where review_text is null\n",
    "data = data.na.drop(subset=[\"review_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4238"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.count() # Removed!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------------------------------+-----------------------------------------------------------------------------------------------+------------+----------+--------------+----------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|X  |book_title                    |review_title                                                                                   |review_user |book_id   |review_id     |timestamp |review_text                                                                                                                                                                                                                        |review_score|text                                                                                                                                                                                                                                                                                                                   |\n",
      "+---+------------------------------+-----------------------------------------------------------------------------------------------+------------+----------+--------------+----------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|1  |A Gentleman in Moscow: A Novel|Russian aristocracy following the Russian Revolution                                           |Kansabelle  |0143110438|R2UFCQ9WES7VFH|1555241537|A great read. In addition to the plot, characters, hidden treasure etc. I enjoyed the philosophical question: do Russians destroy more of what they create more than other cultures? Even if you stick to the characters-great fun.|4           |A Gentleman in Moscow: A Novel Russian aristocracy following the Russian Revolution A great read. In addition to the plot, characters, hidden treasure etc. I enjoyed the philosophical question: do Russians destroy more of what they create more than other cultures? Even if you stick to the characters-great fun.|\n",
      "|2  |A Gentleman in Moscow: A Novel|Knowing nothing ahead of time just walk into the story without expectations and become charmed.|D.P. McHenry|0143110438|R24B1HA9J9I99G|1555241542|Great story, well told. Characters were well developed. Ending was perfect!                                                                                                                                                        |4           |A Gentleman in Moscow: A Novel Knowing nothing ahead of time just walk into the story without expectations and become charmed. Great story, well told. Characters were well developed. Ending was perfect!                                                                                                             |\n",
      "+---+------------------------------+-----------------------------------------------------------------------------------------------+------------+----------+--------------+----------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Concatenate book_title, review_title and review_text into a single column\n",
    "from pyspark.sql import functions as ff\n",
    "data = data.withColumn('text', ff.concat(ff.col('book_title'),\n",
    "                                              ff.lit(' '), \n",
    "                                              ff.col('review_title'),\n",
    "                                             ff.lit(' '),\n",
    "                                             ff.col('review_text')))\n",
    "data.show(2, truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------------------+\n",
      "|review_score|                text|\n",
      "+------------+--------------------+\n",
      "|           4|A Gentleman in Mo...|\n",
      "|           4|A Gentleman in Mo...|\n",
      "|           4|Pet Sematary: A N...|\n",
      "|           4|Less (Winner of t...|\n",
      "|           4|Supermarket AMAZI...|\n",
      "+------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "drop_list = ['X', 'book_title', 'review_title', 'review_user', 'book_id', 'review_id', \n",
    "             'timestamp', 'review_text']\n",
    "data = data.select([column for column in data.columns if column not in drop_list])\n",
    "data.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Now the modelling pipeline starts</h3>\n",
    "I got it from: https://towardsdatascience.com/multi-class-text-classification-with-pyspark-7d78d022ed35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import RegexTokenizer, StopWordsRemover, CountVectorizer\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "import nltk\n",
    "#nltk.download(\"stopwords\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regular expression tokenizer: To split sentences into words\n",
    "regexTokenizer = RegexTokenizer(inputCol=\"text\", outputCol=\"words\", pattern=\"\\\\W\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stop words\n",
    "stopwordList = nltk.corpus.stopwords.words('english')\n",
    "stopwordsRemover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered\", stopWords=stopwordList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bag of words count\n",
    "countVectors = CountVectorizer(inputCol=\"filtered\", outputCol=\"features\", vocabSize=20000, minDF=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer, VectorAssembler\n",
    "\n",
    "label_stringIdx = StringIndexer(inputCol = \"review_score\", outputCol = \"label\") # Recoding target variable\n",
    "labels_stars = label_stringIdx.fit(trainingData).labels # Save this levels to be able later to transform back\n",
    "\n",
    "pipeline = Pipeline(stages=[regexTokenizer, stopwordsRemover, countVectors, label_stringIdx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataset Count: 3333\n",
      "Test Dataset Count: 905\n"
     ]
    }
   ],
   "source": [
    "# set seed for reproducibility\n",
    "(trainingData, testData) = data.randomSplit([0.8, 0.2], seed = 12345)\n",
    "print(\"Training Dataset Count: \" + str(trainingData.count()))\n",
    "print(\"Test Dataset Count: \" + str(testData.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------------------+--------------------+--------------------+--------------------+-----+\n",
      "|review_score|                text|               words|            filtered|            features|label|\n",
      "+------------+--------------------+--------------------+--------------------+--------------------+-----+\n",
      "|           1|A Gentleman in Mo...|[a, gentleman, in...|[gentleman, mosco...|(453,[0,1,3,5,6,1...|  4.0|\n",
      "|           1|A Gentleman in Mo...|[a, gentleman, in...|[gentleman, mosco...|(453,[1,2,3,5,6,8...|  4.0|\n",
      "|           1|A Gentleman in Mo...|[a, gentleman, in...|[gentleman, mosco...|(453,[0,1,3,5,6,3...|  4.0|\n",
      "|           1|A Gentleman in Mo...|[a, gentleman, in...|[gentleman, mosco...|(453,[0,1,4,5,6,1...|  4.0|\n",
      "|           1|After (The After ...|[after, the, afte...|[series, eye, rol...|(453,[0,3,4,7,11,...|  4.0|\n",
      "+------------+--------------------+--------------------+--------------------+--------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Fit the pipeline to training documents.\n",
    "pipelineFit = pipeline.fit(trainingData)\n",
    "dataset = pipelineFit.transform(trainingData)\n",
    "#dataset.show(1, truncate = False)\n",
    "dataset.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------------------+--------------------+--------------------+--------------------+-----+\n",
      "|review_score|                text|               words|            filtered|            features|label|\n",
      "+------------+--------------------+--------------------+--------------------+--------------------+-----+\n",
      "|           1|A Gentleman in Mo...|[a, gentleman, in...|[gentleman, mosco...|(453,[1,2,3,4,5,6...|  4.0|\n",
      "|           1|After (The After ...|[after, the, afte...|[series, baid, sw...|(453,[1,27,94,260...|  4.0|\n",
      "|           1|After (The After ...|[after, the, afte...|[series, waste, t...|(453,[0,9,14,15,4...|  4.0|\n",
      "|           1|Cemetery Road: A ...|[cemetery, road, ...|[cemetery, road, ...|(453,[0,1,15,131,...|  4.0|\n",
      "|           1|Cemetery Road: A ...|[cemetery, road, ...|[cemetery, road, ...|(453,[1,14,32,58,...|  4.0|\n",
      "+------------+--------------------+--------------------+--------------------+--------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_dataset = pipelineFit.transform(testData)\n",
    "#test_dataset.show(1, truncate = False)\n",
    "test_dataset.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----+\n",
      "|review_score|count|\n",
      "+------------+-----+\n",
      "|           5| 2543|\n",
      "|           4|  466|\n",
      "|           3|  146|\n",
      "|           2|   90|\n",
      "|           1|   88|\n",
      "+------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Original encoding\n",
    "trainingData.groupBy(\"review_score\") \\\n",
    "    .count() \\\n",
    "    .orderBy(col(\"count\").desc()) \\\n",
    "    .show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|label|count|\n",
      "+-----+-----+\n",
      "|  0.0| 2543|\n",
      "|  1.0|  466|\n",
      "|  2.0|  146|\n",
      "|  3.0|   90|\n",
      "|  4.0|   88|\n",
      "+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Show how the encoding changed\n",
    "dataset.groupBy(\"label\") \\\n",
    "    .count() \\\n",
    "    .orderBy(col(\"count\").desc()) \\\n",
    "    .show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Logistic regression using count vector features</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------+------------+------------------------------+-----+----------+\n",
      "|                          text|review_score|                   probability|label|prediction|\n",
      "+------------------------------+------------+------------------------------+-----+----------+\n",
      "|The Woman in the Window: A ...|           4|[1.0,2.17284525898869E-18,4...|  1.0|       0.0|\n",
      "|First: Sandra Day O'Connor ...|           5|[0.9999999999999467,5.31921...|  0.0|       0.0|\n",
      "|QAnon: An Invitation to The...|           5|[0.9999999999986744,1.13697...|  0.0|       0.0|\n",
      "|Someone Knows Another great...|           5|[0.9999999999485647,5.14352...|  0.0|       0.0|\n",
      "|The Red Scrolls of Magic (T...|           3|[0.999999999414569,4.332639...|  2.0|       0.0|\n",
      "|The Mister Creating your ow...|           5|[0.9999999637776866,3.61965...|  0.0|       0.0|\n",
      "|The Woman in the Window: A ...|           5|[0.9999999544060393,5.58719...|  0.0|       0.0|\n",
      "|Pet Sematary: A Novel Facin...|           5|[0.9999999527766081,4.72233...|  0.0|       0.0|\n",
      "|Daisy Jones & The Six: A No...|           4|[0.9999998823087043,1.17681...|  1.0|       0.0|\n",
      "|The Prairie Homestead Cookb...|           5|[0.9999998411959269,1.57716...|  0.0|       0.0|\n",
      "+------------------------------+------------+------------------------------+-----+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(maxIter=20, regParam=0, elasticNetParam=0)\n",
    "lrModel = lr.fit(dataset)\n",
    "predictions = lrModel.transform(test_dataset)\n",
    "predictions.filter(predictions['prediction'] == 0) \\\n",
    "    .select(\"text\",\"review_score\",\"probability\",\"label\",\"prediction\") \\\n",
    "    .orderBy(\"probability\", ascending=False) \\\n",
    "    .show(n = 10, truncate = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7033916817155373"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "evaluator.evaluate(predictions) # This is the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import IndexToString\n",
    "# Saving levels \n",
    "# Transform back from index to original coding\n",
    "labelConverter = IndexToString(inputCol=\"prediction\", outputCol=\"predictedScore\", labels = labels_stars)\n",
    "predictions = labelConverter.transform(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(review_score=1, text=\"A Gentleman in Moscow: A Novel Too slow This has to be one of the most boring books I've read.  It takes chapters upon chapters to move the story forward.  I stopped reading after then seventh chapter\", words=['a', 'gentleman', 'in', 'moscow', 'a', 'novel', 'too', 'slow', 'this', 'has', 'to', 'be', 'one', 'of', 'the', 'most', 'boring', 'books', 'i', 've', 'read', 'it', 'takes', 'chapters', 'upon', 'chapters', 'to', 'move', 'the', 'story', 'forward', 'i', 'stopped', 'reading', 'after', 'then', 'seventh', 'chapter'], filtered=['gentleman', 'moscow', 'novel', 'slow', 'one', 'boring', 'books', 'read', 'takes', 'chapters', 'upon', 'chapters', 'move', 'story', 'forward', 'stopped', 'reading', 'seventh', 'chapter'], features=SparseVector(453, {1: 1.0, 2: 1.0, 3: 1.0, 4: 1.0, 5: 1.0, 6: 1.0, 15: 1.0, 19: 1.0, 135: 1.0, 197: 1.0, 199: 1.0, 223: 1.0, 328: 2.0, 379: 1.0}), label=4.0, rawPrediction=DenseVector([0.6379, 0.0223, -0.0876, 1.61, -2.1826]), probability=DenseVector([0.2115, 0.1143, 0.1024, 0.5592, 0.0126]), prediction=3.0, predictedScore='2')]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Crossvalidation </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7261842626917203"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "\n",
    "lr = LogisticRegression(maxIter=20, regParam=0, elasticNetParam=0)\n",
    "\n",
    "# Create ParamGrid for Cross Validation\n",
    "paramGrid = (ParamGridBuilder()\n",
    "             .addGrid(lr.regParam, [0.01, 0.05, 0.1, 0.2, 0.3, 0.5]) # regularization parameter\n",
    "             .addGrid(lr.elasticNetParam, [0.0, 0.2, 0.4, 0.6, 0.8, 1]) # Elastic Net Parameter (Ridge = 0)\n",
    "#            .addGrid(model.maxIter, [10, 20, 50]) #Number of iterations\n",
    "#            .addGrid(idf.numFeatures, [10, 100, 1000]) # Number of features\n",
    "             .build())\n",
    "\n",
    "# Create 5-fold CrossValidator\n",
    "cv = CrossValidator(estimator=lr, \\\n",
    "                    estimatorParamMaps=paramGrid, \\\n",
    "                    evaluator=evaluator, \\\n",
    "                    numFolds=5)\n",
    "\n",
    "cvModel = cv.fit(dataset)\n",
    "\n",
    "predictions = cvModel.transform(test_dataset)\n",
    "predictions = labelConverter.transform(predictions) # Transform labels\n",
    "\n",
    "# Evaluate best model\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\", labelCol=\"label\")\n",
    "evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "predictions.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To evaluate and get confusion matrix: https://runawayhorse001.github.io/LearningApacheSpark/classification.html\n",
    "#from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "#metrics = MulticlassMetrics(predictionCol=\"predictions\", labelCol=\"label\")\n",
    "#metrics.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Logistic Regression using TF-IDF Features</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import HashingTF, IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "hashingTF = HashingTF(inputCol=\"filtered\", outputCol=\"rawFeatures\", numFeatures=20000)\n",
    "idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\", minDocFreq=5) #minDocFreq: remove sparse terms\n",
    "pipeline_tfidf = Pipeline(stages=[regexTokenizer, stopwordsRemover, hashingTF, idf, label_stringIdx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------------------+--------------------+--------------------+--------------------+--------------------+-----+\n",
      "|review_score|                text|               words|            filtered|         rawFeatures|            features|label|\n",
      "+------------+--------------------+--------------------+--------------------+--------------------+--------------------+-----+\n",
      "|           1|A Gentleman in Mo...|[a, gentleman, in...|[gentleman, mosco...|(20000,[702,1106,...|(20000,[702,1106,...|  4.0|\n",
      "+------------+--------------------+--------------------+--------------------+--------------------+--------------------+-----+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# applying pipeline to training data\n",
    "pipelineFit_tfidf = pipeline_tfidf.fit(trainingData)\n",
    "dataset_tfidf = pipelineFit_tfidf.transform(trainingData)\n",
    "dataset_tfidf.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------------------+--------------------+--------------------+--------------------+--------------------+-----+\n",
      "|review_score|                text|               words|            filtered|         rawFeatures|            features|label|\n",
      "+------------+--------------------+--------------------+--------------------+--------------------+--------------------+-----+\n",
      "|           1|A Gentleman in Mo...|[a, gentleman, in...|[gentleman, mosco...|(20000,[415,591,2...|(20000,[415,591,2...|  4.0|\n",
      "+------------+--------------------+--------------------+--------------------+--------------------+--------------------+-----+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_dataset_tfidf = pipelineFit_tfidf.transform(testData)\n",
    "test_dataset_tfidf.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------+------------------------------+------------+--------------+\n",
      "|                          text|                   probability|review_score|predictedScore|\n",
      "+------------------------------+------------------------------+------------+--------------+\n",
      "|Pet Sematary: A Novel perfe...|[1.0,1.0815308445822547E-16...|           4|             5|\n",
      "|The Island of Sea Women: A ...|[1.0,8.278481062705543E-17,...|           5|             5|\n",
      "|Cat and Nat's Mom Truths: E...|[1.0,3.097684754256849E-17,...|           5|             5|\n",
      "|The Mister EL JAMES did it ...|[1.0,2.041465137202726E-17,...|           5|             5|\n",
      "|Unlearn: 101 Simple Truths ...|[1.0,1.8135263570340965E-17...|           5|             5|\n",
      "|Eat to Beat Disease: The Ne...|[1.0,3.570469271328641E-18,...|           5|             5|\n",
      "|Run Away Harlan Coben at Hi...|[1.0,1.372681552457108E-18,...|           4|             5|\n",
      "|Accidental Presidents: Eigh...|[1.0,1.3361246436745188E-18...|           5|             5|\n",
      "|Can't Make This Stuff Up!: ...|[1.0,1.0674685566433387E-18...|           5|             5|\n",
      "|A Gentleman in Moscow: A No...|[1.0,5.933782272403053E-19,...|           5|             5|\n",
      "+------------------------------+------------------------------+------------+--------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr_tfidf = LogisticRegression(maxIter=20, regParam=0, elasticNetParam=0)\n",
    "lrModel_tfidf = lr_tfidf.fit(dataset_tfidf)\n",
    "predictions_tfidf = lrModel_tfidf.transform(test_dataset_tfidf)\n",
    "predictions_tfidf = labelConverter.transform(predictions_tfidf) # Transform labels\n",
    "predictions_tfidf.filter(predictions_tfidf['prediction'] == 0) \\\n",
    "    .select(\"text\",\"probability\",\"review_score\",\"predictedScore\") \\\n",
    "    .orderBy(\"probability\", ascending=False) \\\n",
    "    .show(n = 10, truncate = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----+-------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------+----------+--------------+\n",
      "|review_score|text                                                                                                                                                                                                    |words                                                                                                                                                                                                                                     |filtered                                                                                                                                             |rawFeatures                                                                                                                                                                        |features                                                                                                                                                                                                                                                                                                                                                                                                                                     |label|rawPrediction                                                                                    |probability                                                                                              |prediction|predictedScore|\n",
      "+------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----+-------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------+----------+--------------+\n",
      "|1           |A Gentleman in Moscow: A Novel Too slow This has to be one of the most boring books I've read.  It takes chapters upon chapters to move the story forward.  I stopped reading after then seventh chapter|[a, gentleman, in, moscow, a, novel, too, slow, this, has, to, be, one, of, the, most, boring, books, i, ve, read, it, takes, chapters, upon, chapters, to, move, the, story, forward, i, stopped, reading, after, then, seventh, chapter]|[gentleman, moscow, novel, slow, one, boring, books, read, takes, chapters, upon, chapters, move, story, forward, stopped, reading, seventh, chapter]|(20000,[415,591,2044,3851,4300,5290,5499,7044,7650,9504,11997,16282,16657,16735,17252,18203,18834,19254],[1.0,2.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])|(20000,[415,591,2044,3851,4300,5290,5499,7044,7650,9504,11997,16282,16657,16735,17252,18203,18834,19254],[1.891337893211,7.75564311742696,1.32408308100116,1.31958363583993,2.007134830895754,3.669276806820423,0.5317386453661985,4.122944016746465,0.7900783495223835,3.4297968361865196,5.339339341070958,4.261780461600681,1.4323288774663563,4.710730681648584,1.31846193073073,3.214088263359828,5.627021413522739,3.4390992288488333])|4.0  |[10.120671446659522,-11.007706386031584,-3.7636583546066458,3.5389147108056607,1.111778583173045]|[0.9984936079248447,6.658975004134868E-10,9.32089190302031E-7,0.001383326374809768,1.2213294525790938E-4]|0.0       |5             |\n",
      "+------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----+-------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------+----------+--------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions_tfidf.show(1, truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7211881145739505"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator_tfidf = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "evaluator_tfidf.evaluate(predictions_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Cross-validation</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mnext\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    758\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 759\u001b[1;33m                 \u001b[0mitem\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_items\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpopleft\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    760\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: pop from an empty deque",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-a271fb81e19b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m                     numFolds=10)\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m \u001b[0mcvModel_tfidf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset_tfidf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[0mpredictions_tfidf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcvModel_tfidf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_dataset_tfidf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\spark\\spark-2.4.0-bin-hadoop2.7\\python\\pyspark\\ml\\base.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, dataset, params)\u001b[0m\n\u001b[0;32m    130\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    131\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 132\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    133\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    134\u001b[0m             raise ValueError(\"Params must be either a param map or a list/tuple of param maps, \"\n",
      "\u001b[1;32m~\\Desktop\\spark\\spark-2.4.0-bin-hadoop2.7\\python\\pyspark\\ml\\tuning.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, dataset)\u001b[0m\n\u001b[0;32m    302\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    303\u001b[0m             \u001b[0mtasks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_parallelFitTasks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meva\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcollectSubModelsParam\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 304\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msubModel\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpool\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimap_unordered\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    305\u001b[0m                 \u001b[0mmetrics\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mmetric\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mnFolds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    306\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mcollectSubModelsParam\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mnext\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    761\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_index\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_length\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    762\u001b[0m                     \u001b[1;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 763\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    764\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    765\u001b[0m                     \u001b[0mitem\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_items\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpopleft\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    294\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m    \u001b[1;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    295\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 296\u001b[1;33m                 \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    298\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "lr_tfidf = LogisticRegression(maxIter=20, regParam=0, elasticNetParam=0)\n",
    "\n",
    "# Create ParamGrid for Cross Validation\n",
    "paramGrid = (ParamGridBuilder()\n",
    "             .addGrid(lr.regParam, [0.01, 0.05, 0.1, 0.2, 0.3, 0.5]) # regularization parameter\n",
    "             .addGrid(lr.elasticNetParam, [0.0, 0.2, 0.4, 0.6, 0.8, 1]) # Elastic Net Parameter (Ridge = 0)\n",
    "#            .addGrid(model.maxIter, [10, 20, 50]) #Number of iterations\n",
    "#            .addGrid(idf.numFeatures, [10, 100, 1000]) # Number of features\n",
    "             .build())\n",
    "\n",
    "# Create 5-fold CrossValidator\n",
    "cv = CrossValidator(estimator=lr_tfidf, \\\n",
    "                    estimatorParamMaps=paramGrid, \\\n",
    "                    evaluator=evaluator, \\\n",
    "                    numFolds=5)\n",
    "\n",
    "cvModel_tfidf = cv.fit(dataset_tfidf)\n",
    "\n",
    "predictions_tfidf = cvModel_tfidf.transform(test_dataset_tfidf)\n",
    "predictions_tfidf = labelConverter.transform(predictions_tfidf) # Transform labels\n",
    "\n",
    "# Evaluate best model\n",
    "evaluator_tfidf = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "evaluator_tfidf.evaluate(predictions_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Word2Vec </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Word2Vec\n",
    "\n",
    "w2v = Word2Vec(vectorSize=3, minCount=0, inputCol=\"filtered\", outputCol=\"features\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_w2v = Pipeline(stages=[regexTokenizer, stopwordsRemover, w2v, label_stringIdx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------------------+--------------------+--------------------+--------------------+-----+\n",
      "|review_score|                text|               words|            filtered|            features|label|\n",
      "+------------+--------------------+--------------------+--------------------+--------------------+-----+\n",
      "|           1|A Gentleman in Mo...|[a, gentleman, in...|[gentleman, mosco...|[0.04381944184812...|  4.0|\n",
      "+------------+--------------------+--------------------+--------------------+--------------------+-----+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# applying pipeline to training data\n",
    "pipelineFit_w2v = pipeline_w2v.fit(trainingData)\n",
    "dataset_w2v = pipelineFit_w2v.transform(trainingData)\n",
    "dataset_w2v.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------------------+--------------------+--------------------+--------------------+-----+\n",
      "|review_score|                text|               words|            filtered|            features|label|\n",
      "+------------+--------------------+--------------------+--------------------+--------------------+-----+\n",
      "|           1|A Gentleman in Mo...|[a, gentleman, in...|[gentleman, mosco...|[0.02492030376666...|  4.0|\n",
      "+------------+--------------------+--------------------+--------------------+--------------------+-----+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_dataset_w2v = pipelineFit_w2v.transform(testData)\n",
    "test_dataset_w2v.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------+------------+------------------------------+-----+----------+\n",
      "|                          text|review_score|                   probability|label|prediction|\n",
      "+------------------------------+------------+------------------------------+-----+----------+\n",
      "|Lies My Doctor Told Me Seco...|           5|[0.9646835515630324,0.00309...|  0.0|       0.0|\n",
      "|Lies My Doctor Told Me Seco...|           5|[0.9608090588343119,0.00303...|  0.0|       0.0|\n",
      "|Lies My Doctor Told Me Seco...|           5|[0.9575811593800235,0.00420...|  0.0|       0.0|\n",
      "|Lies My Doctor Told Me Seco...|           5|[0.9548220408240203,0.00547...|  0.0|       0.0|\n",
      "|QAnon: An Invitation to The...|           5|[0.9542220269819321,0.01907...|  0.0|       0.0|\n",
      "|Lies My Doctor Told Me Seco...|           5|[0.9465833107354823,0.00784...|  0.0|       0.0|\n",
      "|Lies My Doctor Told Me Seco...|           5|[0.942610538423865,0.010679...|  0.0|       0.0|\n",
      "|Lies My Doctor Told Me Seco...|           4|[0.9413034219431073,0.00743...|  1.0|       0.0|\n",
      "|Lies My Doctor Told Me Seco...|           5|[0.9412097825881419,0.01157...|  0.0|       0.0|\n",
      "|Lies My Doctor Told Me Seco...|           2|[0.9386808541629383,0.01212...|  3.0|       0.0|\n",
      "+------------------------------+------------+------------------------------+-----+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr_w2v = LogisticRegression(maxIter=20, regParam=0, elasticNetParam=0)\n",
    "lrModel_w2v = lr_w2v.fit(dataset_w2v)\n",
    "predictions_w2v = lrModel_w2v.transform(test_dataset_w2v)\n",
    "predictions_w2v = labelConverter.transform(predictions_w2v) # Transform labels\n",
    "predictions_w2v.filter(predictions_w2v['prediction'] == 0) \\\n",
    "    .select(\"text\",\"probability\",\"review_score\",\"predictedScore\") \\\n",
    "    .orderBy(\"probability\", ascending=False) \\\n",
    "    .show(n = 10, truncate = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------+-------------------------------------------------------------+-----+----------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------+----------+\n",
      "|review_score|text                                                                                                                                                                                                    |words                                                                                                                                                                                                                                     |filtered                                                                                                                                             |features                                                     |label|rawPrediction                                                                                       |probability                                                                                           |prediction|\n",
      "+------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------+-------------------------------------------------------------+-----+----------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------+----------+\n",
      "|1           |A Gentleman in Moscow: A Novel Too slow This has to be one of the most boring books I've read.  It takes chapters upon chapters to move the story forward.  I stopped reading after then seventh chapter|[a, gentleman, in, moscow, a, novel, too, slow, this, has, to, be, one, of, the, most, boring, books, i, ve, read, it, takes, chapters, upon, chapters, to, move, the, story, forward, i, stopped, reading, after, then, seventh, chapter]|[gentleman, moscow, novel, slow, one, boring, books, read, takes, chapters, upon, chapters, move, story, forward, stopped, reading, seventh, chapter]|[0.024920303766664705,0.4134027083453379,0.06604221522023802]|4.0  |[2.2736430996761974,0.8059810089047936,-0.48303091239859275,-1.1526544031102195,-1.4439387930721788]|[0.7403206772417725,0.17061701207793187,0.04701230744109747,0.024065660218199822,0.017984343020998383]|0.0       |\n",
      "+------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------+-------------------------------------------------------------+-----+----------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------+----------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions_w2v.show(1, truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.670660555402759"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator_w2v = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "evaluator_w2v.evaluate(predictions_w2v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Cross-validation</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mnext\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    758\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 759\u001b[1;33m                 \u001b[0mitem\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_items\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpopleft\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    760\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: pop from an empty deque",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-a271fb81e19b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m                     numFolds=10)\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m \u001b[0mcvModel_tfidf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset_tfidf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[0mpredictions_tfidf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcvModel_tfidf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_dataset_tfidf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\spark\\spark-2.4.0-bin-hadoop2.7\\python\\pyspark\\ml\\base.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, dataset, params)\u001b[0m\n\u001b[0;32m    130\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    131\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 132\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    133\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    134\u001b[0m             raise ValueError(\"Params must be either a param map or a list/tuple of param maps, \"\n",
      "\u001b[1;32m~\\Desktop\\spark\\spark-2.4.0-bin-hadoop2.7\\python\\pyspark\\ml\\tuning.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, dataset)\u001b[0m\n\u001b[0;32m    302\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    303\u001b[0m             \u001b[0mtasks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_parallelFitTasks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meva\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcollectSubModelsParam\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 304\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msubModel\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpool\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimap_unordered\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    305\u001b[0m                 \u001b[0mmetrics\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mmetric\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mnFolds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    306\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mcollectSubModelsParam\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mnext\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    761\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_index\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_length\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    762\u001b[0m                     \u001b[1;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 763\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    764\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    765\u001b[0m                     \u001b[0mitem\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_items\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpopleft\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    294\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m    \u001b[1;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    295\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 296\u001b[1;33m                 \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    298\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "lr_w2v = LogisticRegression(maxIter=20, regParam=0, elasticNetParam=0)\n",
    "\n",
    "# Create ParamGrid for Cross Validation\n",
    "paramGrid = (ParamGridBuilder()\n",
    "             .addGrid(lr.regParam, [0.01, 0.05, 0.1, 0.2, 0.3, 0.5]) # regularization parameter\n",
    "             .addGrid(lr.elasticNetParam, [0.0, 0.2, 0.4, 0.6, 0.8, 1]) # Elastic Net Parameter (Ridge = 0)\n",
    "#            .addGrid(model.maxIter, [10, 20, 50]) #Number of iterations\n",
    "#            .addGrid(idf.numFeatures, [10, 100, 1000]) # Number of features\n",
    "             .build())\n",
    "\n",
    "# Create 5-fold CrossValidator\n",
    "cv = CrossValidator(estimator=lr_w2v, \\\n",
    "                    estimatorParamMaps=paramGrid, \\\n",
    "                    evaluator=evaluator, \\\n",
    "                    numFolds=5)\n",
    "\n",
    "cvModel_w2v = cv.fit(dataset_w2v)\n",
    "\n",
    "predictions_w2v = cvModel_w2v.transform(test_dataset_w2v)\n",
    "predictions_w2v = labelConverter.transform(predictions_w2v) # Transform labels\n",
    "\n",
    "# Evaluate best model\n",
    "evaluator_w2v = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "evaluator_w2v.evaluate(predictions_w2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Naive Bayes</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------+------------+------------------------------+-----+----------+\n",
      "|                          text|review_score|                   probability|label|prediction|\n",
      "+------------------------------+------------+------------------------------+-----+----------+\n",
      "|A Gentleman in Moscow: A No...|           5|[1.0,9.770840117995038E-17,...|  0.0|       0.0|\n",
      "|A Gentleman in Moscow: A No...|           5|[1.0,8.261090898410058E-17,...|  0.0|       0.0|\n",
      "|Lies My Doctor Told Me Seco...|           5|[1.0,5.948914789946586E-17,...|  0.0|       0.0|\n",
      "|Less (Winner of the Pulitze...|           5|[1.0,5.816130134888463E-17,...|  0.0|       0.0|\n",
      "|A Gentleman in Moscow: A No...|           5|[1.0,5.81060272265125E-17,5...|  0.0|       0.0|\n",
      "|Can't Make This Stuff Up!: ...|           5|[1.0,5.635006428149414E-17,...|  0.0|       0.0|\n",
      "|Pet Sematary: A Novel Great...|           4|[1.0,5.348160890282632E-17,...|  1.0|       0.0|\n",
      "|Pet Sematary: A Novel Shine...|           5|[1.0,4.5550547500523756E-17...|  0.0|       0.0|\n",
      "|QAnon: An Invitation to The...|           5|[1.0,3.8639693311275677E-17...|  0.0|       0.0|\n",
      "|A Gentleman in Moscow: A No...|           5|[1.0,3.074125155760129E-17,...|  0.0|       0.0|\n",
      "+------------------------------+------------+------------------------------+-----+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import NaiveBayes\n",
    "nb = NaiveBayes(smoothing=1)\n",
    "model = nb.fit(dataset)\n",
    "predictions = model.transform(test_dataset)\n",
    "predictions = labelConverter.transform(predictions) # Transform labels\n",
    "predictions.filter(predictions['prediction'] == 0) \\\n",
    "    .select(\"text\",\"probability\",\"review_score\",\"predictedScore\") \\\n",
    "    .orderBy(\"probability\", ascending=False) \\\n",
    "    .show(n = 10, truncate = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7299769820931572"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Naive Bayes TF-IDF</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------+------------+------------------------------+-----+----------+\n",
      "|                          text|review_score|                   probability|label|prediction|\n",
      "+------------------------------+------------+------------------------------+-----+----------+\n",
      "|A Gentleman in Moscow: A No...|           5|[1.0,9.770840117995038E-17,...|  0.0|       0.0|\n",
      "|A Gentleman in Moscow: A No...|           5|[1.0,8.261090898410058E-17,...|  0.0|       0.0|\n",
      "|Lies My Doctor Told Me Seco...|           5|[1.0,5.948914789946586E-17,...|  0.0|       0.0|\n",
      "|Less (Winner of the Pulitze...|           5|[1.0,5.816130134888463E-17,...|  0.0|       0.0|\n",
      "|A Gentleman in Moscow: A No...|           5|[1.0,5.81060272265125E-17,5...|  0.0|       0.0|\n",
      "|Can't Make This Stuff Up!: ...|           5|[1.0,5.635006428149414E-17,...|  0.0|       0.0|\n",
      "|Pet Sematary: A Novel Great...|           4|[1.0,5.348160890282632E-17,...|  1.0|       0.0|\n",
      "|Pet Sematary: A Novel Shine...|           5|[1.0,4.5550547500523756E-17...|  0.0|       0.0|\n",
      "|QAnon: An Invitation to The...|           5|[1.0,3.8639693311275677E-17...|  0.0|       0.0|\n",
      "|A Gentleman in Moscow: A No...|           5|[1.0,3.074125155760129E-17,...|  0.0|       0.0|\n",
      "+------------------------------+------------+------------------------------+-----+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "nb_tfidf = NaiveBayes(smoothing=1)\n",
    "model_tfidf = nb_tfidf.fit(dataset_tfidf)\n",
    "predictions_tfidf = model_tfidf.transform(test_dataset_tfidf)\n",
    "predictions_tfidf = labelConverter.transform(predictions_tfidf) # Transform labels\n",
    "predictions_tfidf.filter(predictions_tfidf['prediction'] == 0) \\\n",
    "    .select(\"text\",\"probability\",\"review_score\",\"predictedScore\") \\\n",
    "    .orderBy(\"probability\", ascending=False) \\\n",
    "    .show(n = 10, truncate = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7299769820931572"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator_tfidf = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "evaluator_tfidf.evaluate(predictions_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Random Forest</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------+------------+------------------------------+-----+----------+\n",
      "|                   review_text|review_score|                   probability|label|prediction|\n",
      "+------------------------------+------------+------------------------------+-----+----------+\n",
      "|Loved this story. Beautiful...|           4|[0.7836402391282297,0.12735...|  1.0|       0.0|\n",
      "|Very informative about Keto...|           5|[0.7836402391282297,0.12735...|  0.0|       0.0|\n",
      "|One of the most enjoyable b...|           5|[0.7836402391282297,0.12735...|  0.0|       0.0|\n",
      "|                Wonderful book|           4|[0.7836402391282297,0.12735...|  1.0|       0.0|\n",
      "|Love the easy to follow roa...|           5|[0.7830368095617698,0.12784...|  0.0|       0.0|\n",
      "|Poignant and very satisfyin...|           5|[0.7828176595848821,0.12763...|  0.0|       0.0|\n",
      "|Wonderful book. Beautiful p...|           5|[0.7827614778707869,0.12824...|  0.0|       0.0|\n",
      "|Well written,wonderful char...|           5|[0.7827614778707869,0.12824...|  0.0|       0.0|\n",
      "|This novel is historical, p...|           5|[0.78218092057711,0.1280738...|  0.0|       0.0|\n",
      "|Once again Dr. Joe has gift...|           5|[0.7820820230562446,0.12871...|  0.0|       0.0|\n",
      "+------------------------------+------------+------------------------------+-----+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "rf = RandomForestClassifier(labelCol=\"label\", \\\n",
    "                            featuresCol=\"features\", \\\n",
    "                            numTrees = 100, \\\n",
    "                            maxDepth = 4, \\\n",
    "                            maxBins = 32)\n",
    "# Train model with Training Data\n",
    "rfModel = rf.fit(trainingData)\n",
    "predictions = rfModel.transform(testData)\n",
    "predictions.filter(predictions['prediction'] == 0) \\\n",
    "    .select(\"review_text\",\"review_score\",\"probability\",\"label\",\"prediction\") \\\n",
    "    .orderBy(\"probability\", ascending=False) \\\n",
    "    .show(n = 10, truncate = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6777035552331478"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 122.66666599999999,
   "position": {
    "height": "144px",
    "left": "1009px",
    "right": "20px",
    "top": "120px",
    "width": "250px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "block",
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
