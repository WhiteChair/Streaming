{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Data preprocessing</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SQLContext\n",
    "\n",
    "sqlContext = SQLContext(sc)\n",
    "data = sqlContext.read.format('com.databricks.spark.csv').options(header='true', \n",
    "                                                                  inferschema='true', \n",
    "                                                                  quote = '\"', \n",
    "                                                                  escape = '\"',\n",
    "                                                                 multiline = 'true',\n",
    "                                                                 ignoreTrailingWhiteSpace = 'true').load('Data\\\\data.csv')\n",
    "\n",
    "# There were some problems reading the data, here I found the solutions\n",
    "# https://stackoverflow.com/questions/40413526/reading-csv-files-with-quoted-fields-containing-embedded-commas\n",
    "#https://stackoverflow.com/questions/50477857/spark-fails-to-read-csv-when-last-column-name-contains-spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+--------------------+--------------+----------+--------------+----------+--------------------+------------+\n",
      "|  X|          book_title|        review_title|   review_user|   book_id|     review_id| timestamp|         review_text|review_score|\n",
      "+---+--------------------+--------------------+--------------+----------+--------------+----------+--------------------+------------+\n",
      "|  1|A Gentleman in Mo...|Russian aristocra...|    Kansabelle|0143110438|R2UFCQ9WES7VFH|1555241537|A great read. In ...|           4|\n",
      "|  2|A Gentleman in Mo...|Knowing nothing a...|  D.P. McHenry|0143110438|R24B1HA9J9I99G|1555241542|Great story, well...|           4|\n",
      "|  3|Pet Sematary: A N...|One of King's fin...|Gordon Hoffman|198211598X|R1P137WFADSBYR|1555241649|Only the second n...|           4|\n",
      "|  4|Less (Winner of t...|     Not my favorite|     R. Zocher|0316316121|R35533AKR5CBNS|1555242044|This book is t wh...|           4|\n",
      "|  5|         Supermarket|      AMAZING, BOBBY|    D. Mahoney|1982127139|R1D6LXSDR0CRMN|1555242169|As someone who ha...|           4|\n",
      "+---+--------------------+--------------------+--------------+----------+--------------+----------+--------------------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#drop_list = ['Dates', 'DayOfWeek', 'PdDistrict', 'Resolution', 'Address', 'X', 'Y']\n",
    "#data = data.select([column for column in data.columns if column not in drop_list])\n",
    "data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- X: integer (nullable = true)\n",
      " |-- book_title: string (nullable = true)\n",
      " |-- review_title: string (nullable = true)\n",
      " |-- review_user: string (nullable = true)\n",
      " |-- book_id: string (nullable = true)\n",
      " |-- review_id: string (nullable = true)\n",
      " |-- timestamp: integer (nullable = true)\n",
      " |-- review_text: string (nullable = true)\n",
      " |-- review_score: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----+\n",
      "|review_score|count|\n",
      "+------------+-----+\n",
      "|           5| 3236|\n",
      "|           4|  598|\n",
      "|           3|  187|\n",
      "|           1|  110|\n",
      "|           2|  108|\n",
      "+------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "data.groupBy(\"review_score\") \\\n",
    "    .count() \\\n",
    "    .orderBy(col(\"count\").desc()) \\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4239"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------------+--------------------+-----------+----------+--------------+----------+-----------+------------+\n",
      "|   X|          book_title|        review_title|review_user|   book_id|     review_id| timestamp|review_text|review_score|\n",
      "+----+--------------------+--------------------+-----------+----------+--------------+----------+-----------+------------+\n",
      "|1121|Lies My Doctor To...|This book gave a ...|   mawshell|162860378X|R3SIH2LVO3EYMH|1555252626|       null|           5|\n",
      "+----+--------------------+--------------------+-----------+----------+--------------+----------+-----------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#data.filter(\"review_score is NULL\").show() # No nulls anymore\n",
    "#data.filter(\"X is NULL\").show() \n",
    "#data.filter(\"book_title is NULL\").show()\n",
    "#data.filter(\"review_title is NULL\").show()\n",
    "#data.filter(\"review_user is NULL\").show()\n",
    "#data.filter(\"book_id is NULL\").show()\n",
    "#data.filter(\"review_id is NULL\").show()\n",
    "#data.filter(\"timestamp is NULL\").show()\n",
    "data.filter(\"review_text is NULL\").show() # There is one null\n",
    "#data.filter(\"review_score is NULL\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove observation where review_text is null\n",
    "data = data.na.drop(subset=[\"review_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4238"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.count() # Removed!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------------------------------+-----------------------------------------------------------------------------------------------+------------+----------+--------------+----------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|X  |book_title                    |review_title                                                                                   |review_user |book_id   |review_id     |timestamp |review_text                                                                                                                                                                                                                        |review_score|text                                                                                                                                                                                                                                                                                                                   |\n",
      "+---+------------------------------+-----------------------------------------------------------------------------------------------+------------+----------+--------------+----------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|1  |A Gentleman in Moscow: A Novel|Russian aristocracy following the Russian Revolution                                           |Kansabelle  |0143110438|R2UFCQ9WES7VFH|1555241537|A great read. In addition to the plot, characters, hidden treasure etc. I enjoyed the philosophical question: do Russians destroy more of what they create more than other cultures? Even if you stick to the characters-great fun.|4           |A Gentleman in Moscow: A Novel Russian aristocracy following the Russian Revolution A great read. In addition to the plot, characters, hidden treasure etc. I enjoyed the philosophical question: do Russians destroy more of what they create more than other cultures? Even if you stick to the characters-great fun.|\n",
      "|2  |A Gentleman in Moscow: A Novel|Knowing nothing ahead of time just walk into the story without expectations and become charmed.|D.P. McHenry|0143110438|R24B1HA9J9I99G|1555241542|Great story, well told. Characters were well developed. Ending was perfect!                                                                                                                                                        |4           |A Gentleman in Moscow: A Novel Knowing nothing ahead of time just walk into the story without expectations and become charmed. Great story, well told. Characters were well developed. Ending was perfect!                                                                                                             |\n",
      "+---+------------------------------+-----------------------------------------------------------------------------------------------+------------+----------+--------------+----------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Concatenate book_title, review_title and review_text into a single column\n",
    "from pyspark.sql import functions as ff\n",
    "data = data.withColumn('text', ff.concat(ff.col('book_title'),\n",
    "                                              ff.lit(' '), \n",
    "                                              ff.col('review_title'),\n",
    "                                             ff.lit(' '),\n",
    "                                             ff.col('review_text')))\n",
    "data.show(2, truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------------------+\n",
      "|review_score|                text|\n",
      "+------------+--------------------+\n",
      "|           4|A Gentleman in Mo...|\n",
      "|           4|A Gentleman in Mo...|\n",
      "|           4|Pet Sematary: A N...|\n",
      "|           4|Less (Winner of t...|\n",
      "|           4|Supermarket AMAZI...|\n",
      "+------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "drop_list = ['X', 'book_title', 'review_title', 'review_user', 'book_id', 'review_id', \n",
    "             'timestamp', 'review_text']\n",
    "data = data.select([column for column in data.columns if column not in drop_list])\n",
    "data.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Now the modelling pipeline starts</h3>\n",
    "I got it from: https://towardsdatascience.com/multi-class-text-classification-with-pyspark-7d78d022ed35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import RegexTokenizer, StopWordsRemover, CountVectorizer\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "import nltk\n",
    "#nltk.download(\"stopwords\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataset Count: 3333\n",
      "Test Dataset Count: 905\n"
     ]
    }
   ],
   "source": [
    "# set seed for reproducibility\n",
    "(trainingData, testData) = data.randomSplit([0.8, 0.2], seed = 12345)\n",
    "print(\"Training Dataset Count: \" + str(trainingData.count()))\n",
    "print(\"Test Dataset Count: \" + str(testData.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regular expression tokenizer: To split sentences into words\n",
    "regexTokenizer = RegexTokenizer(inputCol=\"text\", outputCol=\"words\", pattern=\"\\\\W\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stop words\n",
    "stopwordList = nltk.corpus.stopwords.words('english')\n",
    "stopwordsRemover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered\", stopWords=stopwordList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bag of words count\n",
    "countVectors = CountVectorizer(inputCol=\"filtered\", outputCol=\"features\", vocabSize=20000, minDF=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer, VectorAssembler\n",
    "\n",
    "# Recoding target variable\n",
    "label_stringIdx = StringIndexer(inputCol = \"review_score\", outputCol = \"label\") \n",
    "labels_stars = label_stringIdx.fit(trainingData).labels # Save this levels to be able later to transform back\n",
    "\n",
    "# Create pipeline\n",
    "pipeline = Pipeline(stages=[regexTokenizer, stopwordsRemover, countVectors, label_stringIdx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------------------+--------------------+--------------------+--------------------+-----+\n",
      "|review_score|                text|               words|            filtered|            features|label|\n",
      "+------------+--------------------+--------------------+--------------------+--------------------+-----+\n",
      "|           1|A Gentleman in Mo...|[a, gentleman, in...|[gentleman, mosco...|(453,[0,1,3,5,6,1...|  4.0|\n",
      "|           1|A Gentleman in Mo...|[a, gentleman, in...|[gentleman, mosco...|(453,[1,2,3,5,6,8...|  4.0|\n",
      "|           1|A Gentleman in Mo...|[a, gentleman, in...|[gentleman, mosco...|(453,[0,1,3,5,6,3...|  4.0|\n",
      "|           1|A Gentleman in Mo...|[a, gentleman, in...|[gentleman, mosco...|(453,[0,1,4,5,6,1...|  4.0|\n",
      "|           1|After (The After ...|[after, the, afte...|[series, eye, rol...|(453,[0,3,4,7,11,...|  4.0|\n",
      "+------------+--------------------+--------------------+--------------------+--------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Fit the pipeline to training data.\n",
    "pipelineFit = pipeline.fit(trainingData)\n",
    "dataset = pipelineFit.transform(trainingData)\n",
    "#dataset.show(1, truncate = False)\n",
    "dataset.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------------------+--------------------+--------------------+--------------------+-----+\n",
      "|review_score|                text|               words|            filtered|            features|label|\n",
      "+------------+--------------------+--------------------+--------------------+--------------------+-----+\n",
      "|           1|A Gentleman in Mo...|[a, gentleman, in...|[gentleman, mosco...|(453,[1,2,3,4,5,6...|  4.0|\n",
      "|           1|After (The After ...|[after, the, afte...|[series, baid, sw...|(453,[1,27,94,260...|  4.0|\n",
      "|           1|After (The After ...|[after, the, afte...|[series, waste, t...|(453,[0,9,14,15,4...|  4.0|\n",
      "|           1|Cemetery Road: A ...|[cemetery, road, ...|[cemetery, road, ...|(453,[0,1,15,131,...|  4.0|\n",
      "|           1|Cemetery Road: A ...|[cemetery, road, ...|[cemetery, road, ...|(453,[1,14,32,58,...|  4.0|\n",
      "+------------+--------------------+--------------------+--------------------+--------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Fit the pipeline to test data.\n",
    "test_dataset = pipelineFit.transform(testData)\n",
    "#test_dataset.show(1, truncate = False)\n",
    "test_dataset.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----+\n",
      "|review_score|count|\n",
      "+------------+-----+\n",
      "|           5| 2543|\n",
      "|           4|  466|\n",
      "|           3|  146|\n",
      "|           2|   90|\n",
      "|           1|   88|\n",
      "+------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Original encoding\n",
    "trainingData.groupBy(\"review_score\") \\\n",
    "    .count() \\\n",
    "    .orderBy(col(\"count\").desc()) \\\n",
    "    .show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|label|count|\n",
      "+-----+-----+\n",
      "|  0.0| 2543|\n",
      "|  1.0|  466|\n",
      "|  2.0|  146|\n",
      "|  3.0|   90|\n",
      "|  4.0|   88|\n",
      "+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Show how the encoding changed\n",
    "dataset.groupBy(\"label\") \\\n",
    "    .count() \\\n",
    "    .orderBy(col(\"count\").desc()) \\\n",
    "    .show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Logistic regression using count vector features</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import IndexToString\n",
    "\n",
    "# Transform back from index to original coding\n",
    "labelConverter = IndexToString(inputCol=\"prediction\", outputCol=\"predictedScore\", labels = labels_stars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------+------------------------------+------------+--------------+\n",
      "|                          text|                   probability|review_score|predictedScore|\n",
      "+------------------------------+------------------------------+------------+--------------+\n",
      "|The Woman in the Window: A ...|[1.0,2.17284525898869E-18,4...|           4|             5|\n",
      "|First: Sandra Day O'Connor ...|[0.9999999999999467,5.31921...|           5|             5|\n",
      "|QAnon: An Invitation to The...|[0.9999999999986744,1.13697...|           5|             5|\n",
      "|Someone Knows Another great...|[0.9999999999485647,5.14352...|           5|             5|\n",
      "|The Red Scrolls of Magic (T...|[0.999999999414569,4.332639...|           3|             5|\n",
      "|The Mister Creating your ow...|[0.9999999637776866,3.61965...|           5|             5|\n",
      "|The Woman in the Window: A ...|[0.9999999544060393,5.58719...|           5|             5|\n",
      "|Pet Sematary: A Novel Facin...|[0.9999999527766081,4.72233...|           5|             5|\n",
      "|Daisy Jones & The Six: A No...|[0.9999998823087043,1.17681...|           4|             5|\n",
      "|The Prairie Homestead Cookb...|[0.9999998411959269,1.57716...|           5|             5|\n",
      "+------------------------------+------------------------------+------------+--------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(maxIter=20, regParam=0, elasticNetParam=0)\n",
    "\n",
    "lrModel = lr.fit(dataset) # Fit model\n",
    "predictions = lrModel.transform(test_dataset) # Predict\n",
    "predictions = labelConverter.transform(predictions) # Transform labels\n",
    "\n",
    "predictions.filter(predictions['prediction'] == 0) \\\n",
    "    .select(\"text\",\"probability\",\"review_score\",\"predictedScore\") \\\n",
    "    .orderBy(\"probability\", ascending=False) \\\n",
    "    .show(n = 10, truncate = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7033916817155373"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "evaluator.evaluate(predictions) # This is the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(review_score=1, text=\"A Gentleman in Moscow: A Novel Too slow This has to be one of the most boring books I've read.  It takes chapters upon chapters to move the story forward.  I stopped reading after then seventh chapter\", words=['a', 'gentleman', 'in', 'moscow', 'a', 'novel', 'too', 'slow', 'this', 'has', 'to', 'be', 'one', 'of', 'the', 'most', 'boring', 'books', 'i', 've', 'read', 'it', 'takes', 'chapters', 'upon', 'chapters', 'to', 'move', 'the', 'story', 'forward', 'i', 'stopped', 'reading', 'after', 'then', 'seventh', 'chapter'], filtered=['gentleman', 'moscow', 'novel', 'slow', 'one', 'boring', 'books', 'read', 'takes', 'chapters', 'upon', 'chapters', 'move', 'story', 'forward', 'stopped', 'reading', 'seventh', 'chapter'], features=SparseVector(453, {1: 1.0, 2: 1.0, 3: 1.0, 4: 1.0, 5: 1.0, 6: 1.0, 15: 1.0, 19: 1.0, 135: 1.0, 197: 1.0, 199: 1.0, 223: 1.0, 328: 2.0, 379: 1.0}), label=4.0, rawPrediction=DenseVector([1.5018, 0.269, -1.0457, 4.3374, -5.0626]), probability=DenseVector([0.0543, 0.0158, 0.0043, 0.9255, 0.0001]), prediction=3.0, predictedScore='2')]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Crossvalidation </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7261842626917203"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "\n",
    "lr = LogisticRegression(maxIter=20, regParam=0, elasticNetParam=0)\n",
    "\n",
    "# Create ParamGrid for Cross Validation\n",
    "paramGrid = (ParamGridBuilder()\n",
    "             .addGrid(lr.regParam, [0.01, 0.05, 0.1, 0.2, 0.3, 0.5]) # regularization parameter\n",
    "             .addGrid(lr.elasticNetParam, [0.0, 0.2, 0.4, 0.6, 0.8, 1]) # Elastic Net Parameter (Ridge = 0)\n",
    "#            .addGrid(model.maxIter, [10, 20, 50]) #Number of iterations\n",
    "#            .addGrid(idf.numFeatures, [10, 100, 1000]) # Number of features\n",
    "             .build())\n",
    "\n",
    "# Create 5-fold CrossValidator\n",
    "cv = CrossValidator(estimator=lr, \\\n",
    "                    estimatorParamMaps=paramGrid, \\\n",
    "                    evaluator=evaluator, \\\n",
    "                    numFolds=5)\n",
    "\n",
    "cvModel = cv.fit(dataset)\n",
    "\n",
    "predictions = cvModel.transform(test_dataset)\n",
    "predictions = labelConverter.transform(predictions) # Transform labels\n",
    "\n",
    "# Evaluate best model\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\", labelCol=\"label\")\n",
    "evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegressionModel: uid = LogisticRegression_ed633c6d7e1a, numClasses = 5, numFeatures = 453"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model = cvModel.bestModel\n",
    "best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "best_reg_param = best_model._java_obj.getRegParam()\n",
    "best_elasticnet_param = best_model._java_obj.getElasticNetParam()\n",
    "print(best_reg_param);print(best_elasticnet_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------+------------------------------+------------+--------------+\n",
      "|                          text|                   probability|review_score|predictedScore|\n",
      "+------------------------------+------------------------------+------------+--------------+\n",
      "|The Woman in the Window: A ...|[0.999999978876327,1.965497...|           4|             5|\n",
      "|First: Sandra Day O'Connor ...|[0.9999991450731959,7.94014...|           5|             5|\n",
      "|Someone Knows Another great...|[0.9999972860920413,2.66768...|           5|             5|\n",
      "|QAnon: An Invitation to The...|[0.9999671627047327,1.31596...|           5|             5|\n",
      "|The Red Scrolls of Magic (T...|[0.9999485073589646,1.54137...|           3|             5|\n",
      "|The Mister Creating your ow...|[0.9999150742102599,6.23867...|           5|             5|\n",
      "|When We Left Cuba Suspensef...|[0.9998202299922372,1.79740...|           5|             5|\n",
      "|Directorate S: The C.I.A. a...|[0.9998157110227579,1.84287...|           5|             5|\n",
      "|Pet Sematary: A Novel Facin...|[0.9996424992337576,3.57460...|           5|             5|\n",
      "|Lies My Doctor Told Me Seco...|[0.9995196047530555,3.20081...|           4|             5|\n",
      "+------------------------------+------------------------------+------------+--------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.filter(predictions['prediction'] == 0) \\\n",
    "    .select(\"text\",\"probability\",\"review_score\",\"predictedScore\") \\\n",
    "    .orderBy(\"probability\", ascending=False) \\\n",
    "    .show(n = 10, truncate = 30)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "predictions.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To evaluate and get confusion matrix: https://runawayhorse001.github.io/LearningApacheSpark/classification.html\n",
    "#from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "#metrics = MulticlassMetrics(predictionCol=\"predictions\", labelCol=\"label\")\n",
    "#metrics.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Naive Bayes</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------+------------------------------+------------+--------------+\n",
      "|                          text|                   probability|review_score|predictedScore|\n",
      "+------------------------------+------------------------------+------------+--------------+\n",
      "|First: Sandra Day O'Connor ...|[0.9999999995064941,4.86284...|           5|             5|\n",
      "|Lies My Doctor Told Me Seco...|[0.9999977415013812,1.62760...|           5|             5|\n",
      "|Lies My Doctor Told Me Seco...|[0.9999945873950603,5.31709...|           5|             5|\n",
      "|Daisy Jones & The Six: A No...|[0.9999942371903164,5.03477...|           4|             5|\n",
      "|Lies My Doctor Told Me Seco...|[0.9999921809201134,7.53685...|           4|             5|\n",
      "|Lies My Doctor Told Me Seco...|[0.9999870737041547,1.28940...|           5|             5|\n",
      "|Lies My Doctor Told Me Seco...|[0.9999866817292232,1.29695...|           5|             5|\n",
      "|Lies My Doctor Told Me Seco...|[0.9999844440279964,1.37220...|           5|             5|\n",
      "|Lies My Doctor Told Me Seco...|[0.9999820941048758,1.69650...|           5|             5|\n",
      "|QAnon: An Invitation to The...|[0.9999811667002472,1.87809...|           5|             5|\n",
      "+------------------------------+------------------------------+------------+--------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import NaiveBayes\n",
    "\n",
    "nb = NaiveBayes(smoothing=1)\n",
    "\n",
    "model = nb.fit(dataset)\n",
    "predictions = model.transform(test_dataset)\n",
    "predictions = labelConverter.transform(predictions) # Transform labels\n",
    "\n",
    "predictions.filter(predictions['prediction'] == 0) \\\n",
    "    .select(\"text\",\"probability\",\"review_score\",\"predictedScore\") \\\n",
    "    .orderBy(\"probability\", ascending=False) \\\n",
    "    .show(n = 10, truncate = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7049903730296888"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Random Forest</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------+------------------------------+------------+--------------+\n",
      "|                          text|                   probability|review_score|predictedScore|\n",
      "+------------------------------+------------------------------+------------+--------------+\n",
      "|A Gentleman in Moscow: A No...|[0.8025993463262777,0.12106...|           5|             5|\n",
      "|A Gentleman in Moscow: A No...|[0.8012346620322707,0.12235...|           5|             5|\n",
      "|Lies My Doctor Told Me Seco...|[0.8011775690836588,0.12246...|           5|             5|\n",
      "|Girl, Stop Apologizing: A S...|[0.8010832253126122,0.12274...|           5|             5|\n",
      "|Hashimoto’s Food Pharmacolo...|[0.8009293466066767,0.12260...|           5|             5|\n",
      "|This Is Me: Loving the Pers...|[0.8009019768572124,0.12257...|           5|             5|\n",
      "|Lies My Doctor Told Me Seco...|[0.8007807650346179,0.12270...|           5|             5|\n",
      "|A Gentleman in Moscow: A No...|[0.8007615139368367,0.12194...|           5|             5|\n",
      "|QAnon: An Invitation to The...|[0.8003833500174156,0.12303...|           5|             5|\n",
      "|A Gentleman in Moscow: A No...|[0.8003647098877957,0.12218...|           5|             5|\n",
      "+------------------------------+------------------------------+------------+--------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(labelCol=\"label\", \\\n",
    "                            featuresCol=\"features\", \\\n",
    "                            numTrees = 100, \\\n",
    "                            maxDepth = 4, \\\n",
    "                            maxBins = 32)\n",
    "\n",
    "# Train model with Training Data\n",
    "rfModel = rf.fit(dataset)\n",
    "predictions = rfModel.transform(test_dataset)\n",
    "predictions = labelConverter.transform(predictions) # Transform labels\n",
    "\n",
    "predictions.filter(predictions['prediction'] == 0) \\\n",
    "    .select(\"text\",\"probability\",\"review_score\",\"predictedScore\") \\\n",
    "    .orderBy(\"probability\", ascending=False) \\\n",
    "    .show(n = 10, truncate = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6626568462275606"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Crossvalidation </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6826623645296218"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(labelCol=\"label\", \\\n",
    "                            featuresCol=\"features\", \\\n",
    "                            numTrees = 100, \\\n",
    "                            maxDepth = 4)\n",
    "\n",
    "# Create ParamGrid for Cross Validation\n",
    "paramGrid = (ParamGridBuilder()\n",
    "             .addGrid(rf.numTrees, [100, 200, 500]) # regularization parameter\n",
    "             .addGrid(rf.maxDepth, [4, 10, 20]) # Elastic Net Parameter (Ridge = 0)\n",
    "#            .addGrid(model.maxIter, [10, 20, 50]) #Number of iterations\n",
    "#            .addGrid(idf.numFeatures, [10, 100, 1000]) # Number of features\n",
    "             .build())\n",
    "\n",
    "# Create 5-fold CrossValidator\n",
    "cv = CrossValidator(estimator=rf, \\\n",
    "                    estimatorParamMaps=paramGrid, \\\n",
    "                    evaluator=evaluator, \\\n",
    "                    numFolds=5)\n",
    "\n",
    "cvModel = cv.fit(dataset)\n",
    "\n",
    "predictions = cvModel.transform(test_dataset)\n",
    "predictions = labelConverter.transform(predictions) # Transform labels\n",
    "\n",
    "# Evaluate best model\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\", labelCol=\"label\")\n",
    "evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassificationModel (uid=RandomForestClassifier_8d6c20de5c07) with 500 trees"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model = cvModel.bestModel\n",
    "best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "best_numTrees = best_model.getNumTrees\n",
    "best_maxDepth = best_model.getOrDefault('maxDepth')\n",
    "print(best_numTrees);print(best_maxDepth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------+------------------------------+------------+--------------+\n",
      "|                          text|                   probability|review_score|predictedScore|\n",
      "+------------------------------+------------------------------+------------+--------------+\n",
      "|A Gentleman in Moscow: A No...|[0.9077673122826685,0.06315...|           5|             5|\n",
      "|Exceptional You!: 7 Ways to...|[0.9074103142624389,0.06276...|           5|             5|\n",
      "|A Gentleman in Moscow: A No...|[0.9073340976733448,0.06276...|           5|             5|\n",
      "|A Gentleman in Moscow: A No...|[0.9066922542810658,0.06376...|           5|             5|\n",
      "|A Gentleman in Moscow: A No...|[0.9062303795868857,0.06194...|           5|             5|\n",
      "|A Gentleman in Moscow: A No...|[0.9061756563057325,0.06402...|           4|             5|\n",
      "|A Love Letter Life: Pursue ...|[0.9061325932057224,0.06401...|           5|             5|\n",
      "|Lies My Doctor Told Me Seco...|[0.9056915353492222,0.06399...|           5|             5|\n",
      "|A Gentleman in Moscow: A No...|[0.9053798363381278,0.06420...|           5|             5|\n",
      "|Lies My Doctor Told Me Seco...|[0.9052337518228415,0.06334...|           5|             5|\n",
      "+------------------------------+------------------------------+------------+--------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.filter(predictions['prediction'] == 0) \\\n",
    "    .select(\"text\",\"probability\",\"review_score\",\"predictedScore\") \\\n",
    "    .orderBy(\"probability\", ascending=False) \\\n",
    "    .show(n = 10, truncate = 30)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "predictions.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>TF-IDF Features</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import HashingTF, IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "hashingTF = HashingTF(inputCol=\"filtered\", outputCol=\"rawFeatures\", numFeatures=20000)\n",
    "idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\", minDocFreq=5) #minDocFreq: remove sparse terms\n",
    "\n",
    "pipeline_tfidf = Pipeline(stages=[regexTokenizer, stopwordsRemover, hashingTF, idf, label_stringIdx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------------------+--------------------+--------------------+--------------------+--------------------+-----+\n",
      "|review_score|                text|               words|            filtered|         rawFeatures|            features|label|\n",
      "+------------+--------------------+--------------------+--------------------+--------------------+--------------------+-----+\n",
      "|           1|A Gentleman in Mo...|[a, gentleman, in...|[gentleman, mosco...|(20000,[702,1106,...|(20000,[702,1106,...|  4.0|\n",
      "+------------+--------------------+--------------------+--------------------+--------------------+--------------------+-----+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# applying pipeline to training data\n",
    "pipelineFit_tfidf = pipeline_tfidf.fit(trainingData)\n",
    "dataset_tfidf = pipelineFit_tfidf.transform(trainingData)\n",
    "dataset_tfidf.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------------------+--------------------+--------------------+--------------------+--------------------+-----+\n",
      "|review_score|                text|               words|            filtered|         rawFeatures|            features|label|\n",
      "+------------+--------------------+--------------------+--------------------+--------------------+--------------------+-----+\n",
      "|           1|A Gentleman in Mo...|[a, gentleman, in...|[gentleman, mosco...|(20000,[415,591,2...|(20000,[415,591,2...|  4.0|\n",
      "+------------+--------------------+--------------------+--------------------+--------------------+--------------------+-----+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# applying pipeline to test data\n",
    "test_dataset_tfidf = pipelineFit_tfidf.transform(testData)\n",
    "test_dataset_tfidf.show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Logistic regression TF-IDF</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------+------------------------------+------------+--------------+\n",
      "|                          text|                   probability|review_score|predictedScore|\n",
      "+------------------------------+------------------------------+------------+--------------+\n",
      "|Pet Sematary: A Novel perfe...|[1.0,1.0815308445822547E-16...|           4|             5|\n",
      "|The Island of Sea Women: A ...|[1.0,8.278481062705543E-17,...|           5|             5|\n",
      "|Cat and Nat's Mom Truths: E...|[1.0,3.097684754256849E-17,...|           5|             5|\n",
      "|The Mister EL JAMES did it ...|[1.0,2.041465137202726E-17,...|           5|             5|\n",
      "|Unlearn: 101 Simple Truths ...|[1.0,1.8135263570340965E-17...|           5|             5|\n",
      "|Eat to Beat Disease: The Ne...|[1.0,3.570469271328641E-18,...|           5|             5|\n",
      "|Run Away Harlan Coben at Hi...|[1.0,1.372681552457108E-18,...|           4|             5|\n",
      "|Accidental Presidents: Eigh...|[1.0,1.3361246436745188E-18...|           5|             5|\n",
      "|Can't Make This Stuff Up!: ...|[1.0,1.0674685566433387E-18...|           5|             5|\n",
      "|A Gentleman in Moscow: A No...|[1.0,5.933782272403053E-19,...|           5|             5|\n",
      "+------------------------------+------------------------------+------------+--------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr_tfidf = LogisticRegression(maxIter=20, regParam=0, elasticNetParam=0)\n",
    "\n",
    "lrModel_tfidf = lr_tfidf.fit(dataset_tfidf)\n",
    "predictions_tfidf = lrModel_tfidf.transform(test_dataset_tfidf)\n",
    "predictions_tfidf = labelConverter.transform(predictions_tfidf) # Transform labels\n",
    "\n",
    "predictions_tfidf.filter(predictions_tfidf['prediction'] == 0) \\\n",
    "    .select(\"text\",\"probability\",\"review_score\",\"predictedScore\") \\\n",
    "    .orderBy(\"probability\", ascending=False) \\\n",
    "    .show(n = 10, truncate = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7211881145739505"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator_tfidf = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "evaluator_tfidf.evaluate(predictions_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(review_score=1, text=\"A Gentleman in Moscow: A Novel Too slow This has to be one of the most boring books I've read.  It takes chapters upon chapters to move the story forward.  I stopped reading after then seventh chapter\", words=['a', 'gentleman', 'in', 'moscow', 'a', 'novel', 'too', 'slow', 'this', 'has', 'to', 'be', 'one', 'of', 'the', 'most', 'boring', 'books', 'i', 've', 'read', 'it', 'takes', 'chapters', 'upon', 'chapters', 'to', 'move', 'the', 'story', 'forward', 'i', 'stopped', 'reading', 'after', 'then', 'seventh', 'chapter'], filtered=['gentleman', 'moscow', 'novel', 'slow', 'one', 'boring', 'books', 'read', 'takes', 'chapters', 'upon', 'chapters', 'move', 'story', 'forward', 'stopped', 'reading', 'seventh', 'chapter'], rawFeatures=SparseVector(20000, {415: 1.0, 591: 2.0, 2044: 1.0, 3851: 1.0, 4300: 1.0, 5290: 1.0, 5499: 1.0, 7044: 1.0, 7650: 1.0, 9504: 1.0, 11997: 1.0, 16282: 1.0, 16657: 1.0, 16735: 1.0, 17252: 1.0, 18203: 1.0, 18834: 1.0, 19254: 1.0}), features=SparseVector(20000, {415: 1.8913, 591: 7.7556, 2044: 1.3241, 3851: 1.3196, 4300: 2.0071, 5290: 3.6693, 5499: 0.5317, 7044: 4.1229, 7650: 0.7901, 9504: 3.4298, 11997: 5.3393, 16282: 4.2618, 16657: 1.4323, 16735: 4.7107, 17252: 1.3185, 18203: 3.2141, 18834: 5.627, 19254: 3.4391}), label=4.0, rawPrediction=DenseVector([10.1207, -11.0077, -3.7637, 3.5389, 1.1118]), probability=DenseVector([0.9985, 0.0, 0.0, 0.0014, 0.0001]), prediction=0.0, predictedScore='5')]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_tfidf.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Cross-validation</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.737984333434717"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_tfidf = LogisticRegression(maxIter=20, regParam=0, elasticNetParam=0)\n",
    "\n",
    "# Create ParamGrid for Cross Validation\n",
    "paramGrid = (ParamGridBuilder()\n",
    "             .addGrid(lr_tfidf.regParam, [0.01, 0.05, 0.1, 0.2, 0.3, 0.5]) # regularization parameter\n",
    "             .addGrid(lr_tfidf.elasticNetParam, [0.0, 0.2, 0.4, 0.6, 0.8, 1]) # Elastic Net Parameter (Ridge = 0)\n",
    "#            .addGrid(model.maxIter, [10, 20, 50]) #Number of iterations\n",
    "#            .addGrid(idf.numFeatures, [10, 100, 1000]) # Number of features\n",
    "             .build())\n",
    "\n",
    "# Create 5-fold CrossValidator\n",
    "cv_tfidf = CrossValidator(estimator=lr_tfidf, \\\n",
    "                    estimatorParamMaps=paramGrid, \\\n",
    "                    evaluator=evaluator, \\\n",
    "                    numFolds=5)\n",
    "\n",
    "cvModel_tfidf = cv_tfidf.fit(dataset_tfidf)\n",
    "\n",
    "predictions_tfidf = cvModel_tfidf.transform(test_dataset_tfidf)\n",
    "predictions_tfidf = labelConverter.transform(predictions_tfidf) # Transform labels\n",
    "\n",
    "# Evaluate best model\n",
    "evaluator_tfidf = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "evaluator_tfidf.evaluate(predictions_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegressionModel: uid = LogisticRegression_d8fbbc6068b1, numClasses = 5, numFeatures = 20000"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model_tfidf = cvModel_tfidf.bestModel\n",
    "best_model_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01\n",
      "0.2\n"
     ]
    }
   ],
   "source": [
    "best_reg_param_tfidf = best_model_tfidf._java_obj.getRegParam()\n",
    "best_elasticnet_param_tfidf = best_model_tfidf._java_obj.getElasticNetParam()\n",
    "print(best_reg_param_tfidf);print(best_elasticnet_param_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------+------------------------------+------------+--------------+\n",
      "|                          text|                   probability|review_score|predictedScore|\n",
      "+------------------------------+------------------------------+------------+--------------+\n",
      "|Someone Knows Another great...|[0.9999986067796225,9.71800...|           5|             5|\n",
      "|When We Left Cuba Suspensef...|[0.9999962127269121,3.07337...|           5|             5|\n",
      "|First: Sandra Day O'Connor ...|[0.9999525701237956,4.53978...|           5|             5|\n",
      "|Pet Sematary: A Novel Facin...|[0.9999213115576286,7.85227...|           5|             5|\n",
      "|BraveTart: Iconic American ...|[0.9997483263122545,9.94285...|           5|             5|\n",
      "|A Gentleman in Moscow: A No...|[0.9995737652200387,3.02371...|           5|             5|\n",
      "|Nopalito: A Mexican Kitchen...|[0.9995521253691966,1.35291...|           5|             5|\n",
      "|A Gentleman in Moscow: A No...|[0.9993147045538943,1.44494...|           5|             5|\n",
      "|The Mister Creating your ow...|[0.9992236922558627,3.95361...|           5|             5|\n",
      "|A Gentleman in Moscow: A No...|[0.9987995222535707,5.16276...|           5|             5|\n",
      "+------------------------------+------------------------------+------------+--------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions_tfidf.filter(predictions_tfidf['prediction'] == 0) \\\n",
    "    .select(\"text\",\"probability\",\"review_score\",\"predictedScore\") \\\n",
    "    .orderBy(\"probability\", ascending=False) \\\n",
    "    .show(n = 10, truncate = 30)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "predictions_tfidf.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Naive Bayes TF-IDF</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------+------------------------------+------------+--------------+\n",
      "|                          text|                   probability|review_score|predictedScore|\n",
      "+------------------------------+------------------------------+------------+--------------+\n",
      "|A Gentleman in Moscow: A No...|[1.0,9.770840117995038E-17,...|           5|             5|\n",
      "|A Gentleman in Moscow: A No...|[1.0,8.261090898410058E-17,...|           5|             5|\n",
      "|Lies My Doctor Told Me Seco...|[1.0,5.948914789946586E-17,...|           5|             5|\n",
      "|Less (Winner of the Pulitze...|[1.0,5.816130134888463E-17,...|           5|             5|\n",
      "|A Gentleman in Moscow: A No...|[1.0,5.81060272265125E-17,5...|           5|             5|\n",
      "|Can't Make This Stuff Up!: ...|[1.0,5.635006428149414E-17,...|           5|             5|\n",
      "|Pet Sematary: A Novel Great...|[1.0,5.348160890282632E-17,...|           4|             5|\n",
      "|Pet Sematary: A Novel Shine...|[1.0,4.5550547500523756E-17...|           5|             5|\n",
      "|QAnon: An Invitation to The...|[1.0,3.8639693311275677E-17...|           5|             5|\n",
      "|A Gentleman in Moscow: A No...|[1.0,3.074125155760129E-17,...|           5|             5|\n",
      "+------------------------------+------------------------------+------------+--------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nb_tfidf = NaiveBayes(smoothing=1)\n",
    "\n",
    "model_tfidf = nb_tfidf.fit(dataset_tfidf)\n",
    "predictions_tfidf = model_tfidf.transform(test_dataset_tfidf)\n",
    "predictions_tfidf = labelConverter.transform(predictions_tfidf) # Transform labels\n",
    "\n",
    "predictions_tfidf.filter(predictions_tfidf['prediction'] == 0) \\\n",
    "    .select(\"text\",\"probability\",\"review_score\",\"predictedScore\") \\\n",
    "    .orderBy(\"probability\", ascending=False) \\\n",
    "    .show(n = 10, truncate = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7441898341686789"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator_tfidf = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "evaluator_tfidf.evaluate(predictions_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Random Forest TF-IDF</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------+------------------------------+------------+--------------+\n",
      "|                          text|                   probability|review_score|predictedScore|\n",
      "+------------------------------+------------------------------+------------+--------------+\n",
      "|Lies My Doctor Told Me Seco...|[0.7835181621868612,0.12887...|           5|             5|\n",
      "|A Love Letter Life: Pursue ...|[0.781899783057155,0.129488...|           5|             5|\n",
      "|Exceptional You!: 7 Ways to...|[0.78045612728447,0.1302248...|           5|             5|\n",
      "|Lies My Doctor Told Me Seco...|[0.7803228369358045,0.13034...|           5|             5|\n",
      "|Lies My Doctor Told Me Seco...|[0.7802044223825271,0.13059...|           5|             5|\n",
      "|Girl, Stop Apologizing: A S...|[0.7795375119519148,0.13011...|           5|             5|\n",
      "|WOLFPACK: How to Come Toget...|[0.7793085093005128,0.13069...|           5|             5|\n",
      "|Lies My Doctor Told Me Seco...|[0.779175477103831,0.131877...|           5|             5|\n",
      "|Lies My Doctor Told Me Seco...|[0.7789378957154769,0.13146...|           5|             5|\n",
      "|I'll Be Gone in the Dark: O...|[0.7788168996826377,0.12996...|           5|             5|\n",
      "+------------------------------+------------------------------+------------+--------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "\n",
    "rf_tfidf = RandomForestClassifier(labelCol=\"label\", \\\n",
    "                            featuresCol=\"features\", \\\n",
    "                            numTrees = 100, \\\n",
    "                            maxDepth = 4, \\\n",
    "                            maxBins = 32)\n",
    "\n",
    "# Train model with Training Data\n",
    "rfModel_tfidf = rf_tfidf.fit(dataset_tfidf)\n",
    "predictions_tfidf = rfModel_tfidf.transform(test_dataset_tfidf)\n",
    "predictions_tfidf = labelConverter.transform(predictions_tfidf) # Transform labels\n",
    "\n",
    "predictions_tfidf.filter(predictions_tfidf['prediction'] == 0) \\\n",
    "    .select(\"text\",\"probability\",\"review_score\",\"predictedScore\") \\\n",
    "    .orderBy(\"probability\", ascending=False) \\\n",
    "    .show(n = 10, truncate = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6626568462275606"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator_tfidf = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "evaluator_tfidf.evaluate(predictions_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Crossvalidation </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.680264771399809"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_tfidf = RandomForestClassifier(labelCol=\"label\", \\\n",
    "                            featuresCol=\"features\", \\\n",
    "                            numTrees = 100, \\\n",
    "                            maxDepth = 4)\n",
    "\n",
    "# Create ParamGrid for Cross Validation\n",
    "paramGrid = (ParamGridBuilder()\n",
    "             .addGrid(rf_tfidf.numTrees, [100, 200, 500]) # regularization parameter\n",
    "             .addGrid(rf_tfidf.maxDepth, [4, 10, 20]) # Elastic Net Parameter (Ridge = 0)\n",
    "#            .addGrid(model.maxIter, [10, 20, 50]) #Number of iterations\n",
    "#            .addGrid(idf.numFeatures, [10, 100, 1000]) # Number of features\n",
    "             .build())\n",
    "\n",
    "# Create 5-fold CrossValidator\n",
    "cv_tfidf = CrossValidator(estimator=rf_tfidf, \\\n",
    "                    estimatorParamMaps=paramGrid, \\\n",
    "                    evaluator=evaluator, \\\n",
    "                    numFolds=5)\n",
    "\n",
    "cvModel_tfidf = cv_tfidf.fit(dataset_tfidf)\n",
    "\n",
    "predictions_tfidf = cvModel_tfidf.transform(test_dataset_tfidf)\n",
    "predictions_tfidf = labelConverter.transform(predictions_tfidf) # Transform labels\n",
    "\n",
    "# Evaluate best model\n",
    "evaluator_tfidf = MulticlassClassificationEvaluator(predictionCol=\"prediction\", labelCol=\"label\")\n",
    "evaluator_tfidf.evaluate(predictions_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassificationModel (uid=RandomForestClassifier_05f1ed3aab59) with 500 trees"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model_tfidf = cvModel_tfidf.bestModel\n",
    "best_model_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "best_numTrees_tfidf = best_model_tfidf.getNumTrees\n",
    "best_maxDepth_tfidf = best_model_tfidf.getOrDefault('maxDepth')\n",
    "print(best_numTrees_tfidf);print(best_maxDepth_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------+------------------------------+------------+--------------+\n",
      "|                          text|                   probability|review_score|predictedScore|\n",
      "+------------------------------+------------------------------+------------+--------------+\n",
      "|Lies My Doctor Told Me Seco...|[0.8458043649570385,0.09648...|           5|             5|\n",
      "|A Gentleman in Moscow: A No...|[0.844207153971729,0.097321...|           5|             5|\n",
      "|Lies My Doctor Told Me Seco...|[0.8428998225423476,0.09625...|           5|             5|\n",
      "|Can't Make This Stuff Up!: ...|[0.842465196358295,0.096097...|           5|             5|\n",
      "|Lies My Doctor Told Me Seco...|[0.842240359993462,0.095738...|           5|             5|\n",
      "|Lies My Doctor Told Me Seco...|[0.8421765385283241,0.09534...|           5|             5|\n",
      "|Lies My Doctor Told Me Seco...|[0.8418983692358402,0.09508...|           5|             5|\n",
      "|Lies My Doctor Told Me Seco...|[0.8414064631240836,0.09780...|           5|             5|\n",
      "|Lies My Doctor Told Me Seco...|[0.8413041936434449,0.09701...|           5|             5|\n",
      "|Lies My Doctor Told Me Seco...|[0.8394938765273949,0.09540...|           5|             5|\n",
      "+------------------------------+------------------------------+------------+--------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions_tfidf.filter(predictions_tfidf['prediction'] == 0) \\\n",
    "    .select(\"text\",\"probability\",\"review_score\",\"predictedScore\") \\\n",
    "    .orderBy(\"probability\", ascending=False) \\\n",
    "    .show(n = 10, truncate = 30)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "predictions_tfidf.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Word2Vec </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Word2Vec\n",
    "\n",
    "w2v = Word2Vec(vectorSize=3, minCount=0, inputCol=\"filtered\", outputCol=\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_w2v = Pipeline(stages=[regexTokenizer, stopwordsRemover, w2v, label_stringIdx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------------------+--------------------+--------------------+--------------------+-----+\n",
      "|review_score|                text|               words|            filtered|            features|label|\n",
      "+------------+--------------------+--------------------+--------------------+--------------------+-----+\n",
      "|           1|A Gentleman in Mo...|[a, gentleman, in...|[gentleman, mosco...|[0.04381944184812...|  4.0|\n",
      "+------------+--------------------+--------------------+--------------------+--------------------+-----+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# applying pipeline to training data\n",
    "pipelineFit_w2v = pipeline_w2v.fit(trainingData)\n",
    "dataset_w2v = pipelineFit_w2v.transform(trainingData)\n",
    "dataset_w2v.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------------------+--------------------+--------------------+--------------------+-----+\n",
      "|review_score|                text|               words|            filtered|            features|label|\n",
      "+------------+--------------------+--------------------+--------------------+--------------------+-----+\n",
      "|           1|A Gentleman in Mo...|[a, gentleman, in...|[gentleman, mosco...|[0.02492030376666...|  4.0|\n",
      "+------------+--------------------+--------------------+--------------------+--------------------+-----+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# applying pipeline to test data\n",
    "test_dataset_w2v = pipelineFit_w2v.transform(testData)\n",
    "test_dataset_w2v.show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Logistic regression Word2Vec</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------+------------------------------+------------+--------------+\n",
      "|                          text|                   probability|review_score|predictedScore|\n",
      "+------------------------------+------------------------------+------------+--------------+\n",
      "|Lies My Doctor Told Me Seco...|[0.9646835515630324,0.00309...|           5|             5|\n",
      "|Lies My Doctor Told Me Seco...|[0.9608090588343119,0.00303...|           5|             5|\n",
      "|Lies My Doctor Told Me Seco...|[0.9575811593800235,0.00420...|           5|             5|\n",
      "|Lies My Doctor Told Me Seco...|[0.9548220408240203,0.00547...|           5|             5|\n",
      "|QAnon: An Invitation to The...|[0.9542220269819321,0.01907...|           5|             5|\n",
      "|Lies My Doctor Told Me Seco...|[0.9465833107354823,0.00784...|           5|             5|\n",
      "|Lies My Doctor Told Me Seco...|[0.942610538423865,0.010679...|           5|             5|\n",
      "|Lies My Doctor Told Me Seco...|[0.9413034219431073,0.00743...|           4|             5|\n",
      "|Lies My Doctor Told Me Seco...|[0.9412097825881419,0.01157...|           5|             5|\n",
      "|Lies My Doctor Told Me Seco...|[0.9386808541629383,0.01212...|           2|             5|\n",
      "+------------------------------+------------------------------+------------+--------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr_w2v = LogisticRegression(maxIter=20, regParam=0, elasticNetParam=0)\n",
    "\n",
    "lrModel_w2v = lr_w2v.fit(dataset_w2v)\n",
    "predictions_w2v = lrModel_w2v.transform(test_dataset_w2v)\n",
    "predictions_w2v = labelConverter.transform(predictions_w2v) # Transform labels\n",
    "\n",
    "predictions_w2v.filter(predictions_w2v['prediction'] == 0) \\\n",
    "    .select(\"text\",\"probability\",\"review_score\",\"predictedScore\") \\\n",
    "    .orderBy(\"probability\", ascending=False) \\\n",
    "    .show(n = 10, truncate = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(review_score=1, text=\"A Gentleman in Moscow: A Novel Too slow This has to be one of the most boring books I've read.  It takes chapters upon chapters to move the story forward.  I stopped reading after then seventh chapter\", words=['a', 'gentleman', 'in', 'moscow', 'a', 'novel', 'too', 'slow', 'this', 'has', 'to', 'be', 'one', 'of', 'the', 'most', 'boring', 'books', 'i', 've', 'read', 'it', 'takes', 'chapters', 'upon', 'chapters', 'to', 'move', 'the', 'story', 'forward', 'i', 'stopped', 'reading', 'after', 'then', 'seventh', 'chapter'], filtered=['gentleman', 'moscow', 'novel', 'slow', 'one', 'boring', 'books', 'read', 'takes', 'chapters', 'upon', 'chapters', 'move', 'story', 'forward', 'stopped', 'reading', 'seventh', 'chapter'], features=DenseVector([0.0249, 0.4134, 0.066]), label=4.0, rawPrediction=DenseVector([2.2736, 0.806, -0.483, -1.1527, -1.4439]), probability=DenseVector([0.7403, 0.1706, 0.047, 0.0241, 0.018]), prediction=0.0, predictedScore='5')]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_w2v.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.670660555402759"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator_w2v = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "evaluator_w2v.evaluate(predictions_w2v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Cross-validation</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6666906585339133"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_w2v = LogisticRegression(maxIter=20, regParam=0, elasticNetParam=0)\n",
    "\n",
    "# Create ParamGrid for Cross Validation\n",
    "paramGrid = (ParamGridBuilder()\n",
    "             .addGrid(lr_w2v.regParam, [0.01, 0.05, 0.1, 0.2, 0.3, 0.5]) # regularization parameter\n",
    "             .addGrid(lr_w2v.elasticNetParam, [0.0, 0.2, 0.4, 0.6, 0.8, 1]) # Elastic Net Parameter (Ridge = 0)\n",
    "#            .addGrid(model.maxIter, [10, 20, 50]) #Number of iterations\n",
    "#            .addGrid(idf.numFeatures, [10, 100, 1000]) # Number of features\n",
    "             .build())\n",
    "\n",
    "# Create 5-fold CrossValidator\n",
    "cv_w2v = CrossValidator(estimator=lr_w2v, \\\n",
    "                    estimatorParamMaps=paramGrid, \\\n",
    "                    evaluator=evaluator, \\\n",
    "                    numFolds=5)\n",
    "\n",
    "cvModel_w2v = cv_w2v.fit(dataset_w2v)\n",
    "\n",
    "predictions_w2v = cvModel_w2v.transform(test_dataset_w2v)\n",
    "predictions_w2v = labelConverter.transform(predictions_w2v) # Transform labels\n",
    "\n",
    "# Evaluate best model\n",
    "evaluator_w2v = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "evaluator_w2v.evaluate(predictions_w2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegressionModel: uid = LogisticRegression_734075164c93, numClasses = 5, numFeatures = 3"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model_w2v = cvModel_w2v.bestModel\n",
    "best_model_w2v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01\n",
      "0.6\n"
     ]
    }
   ],
   "source": [
    "best_reg_param_w2v = best_model_w2v._java_obj.getRegParam()\n",
    "best_elasticnet_param_w2v = best_model_w2v._java_obj.getElasticNetParam()\n",
    "print(best_reg_param_w2v);print(best_elasticnet_param_w2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------+------------------------------+------------+--------------+\n",
      "|                          text|                   probability|review_score|predictedScore|\n",
      "+------------------------------+------------------------------+------------+--------------+\n",
      "|Lies My Doctor Told Me Seco...|[0.956186641694379,0.017261...|           5|             5|\n",
      "|Lies My Doctor Told Me Seco...|[0.9522357241955557,0.01816...|           5|             5|\n",
      "|Lies My Doctor Told Me Seco...|[0.9473683604019182,0.02109...|           5|             5|\n",
      "|Lies My Doctor Told Me Seco...|[0.9422775268241106,0.02403...|           5|             5|\n",
      "|QAnon: An Invitation to The...|[0.9292004784338718,0.03861...|           5|             5|\n",
      "|Lies My Doctor Told Me Seco...|[0.9275775703652407,0.03081...|           5|             5|\n",
      "|Lies My Doctor Told Me Seco...|[0.9264838176022595,0.03047...|           4|             5|\n",
      "|Lies My Doctor Told Me Seco...|[0.9205518337626275,0.03612...|           5|             5|\n",
      "|Lies My Doctor Told Me Seco...|[0.9197298018526364,0.03580...|           5|             5|\n",
      "|Lies My Doctor Told Me Seco...|[0.9156576616654772,0.03813...|           2|             5|\n",
      "+------------------------------+------------------------------+------------+--------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions_w2v.filter(predictions_w2v['prediction'] == 0) \\\n",
    "    .select(\"text\",\"probability\",\"review_score\",\"predictedScore\") \\\n",
    "    .orderBy(\"probability\", ascending=False) \\\n",
    "    .show(n = 10, truncate = 30)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "predictions_w2v.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Naive Bayes Word2Vec</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o134276.fit.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 22972.0 failed 1 times, most recent failure: Lost task 0.0 in stage 22972.0 (TID 23568, localhost, executor driver): java.lang.IllegalArgumentException: requirement failed: Naive Bayes requires nonnegative feature values but found [-0.012262186447185451,0.22753394624906714,-0.028704270666492157].\r\n\tat scala.Predef$.require(Predef.scala:224)\r\n\tat org.apache.spark.ml.classification.NaiveBayes$.requireNonnegativeValues(NaiveBayes.scala:235)\r\n\tat org.apache.spark.ml.classification.NaiveBayes$$anonfun$trainWithLabelCheck$1$$anonfun$4.apply(NaiveBayes.scala:144)\r\n\tat org.apache.spark.ml.classification.NaiveBayes$$anonfun$trainWithLabelCheck$1$$anonfun$4.apply(NaiveBayes.scala:144)\r\n\tat org.apache.spark.ml.classification.NaiveBayes$$anonfun$trainWithLabelCheck$1$$anonfun$7.apply(NaiveBayes.scala:168)\r\n\tat org.apache.spark.ml.classification.NaiveBayes$$anonfun$trainWithLabelCheck$1$$anonfun$7.apply(NaiveBayes.scala:166)\r\n\tat org.apache.spark.util.collection.ExternalSorter$$anonfun$5.apply(ExternalSorter.scala:189)\r\n\tat org.apache.spark.util.collection.ExternalSorter$$anonfun$5.apply(ExternalSorter.scala:188)\r\n\tat org.apache.spark.util.collection.AppendOnlyMap.changeValue(AppendOnlyMap.scala:150)\r\n\tat org.apache.spark.util.collection.SizeTrackingAppendOnlyMap.changeValue(SizeTrackingAppendOnlyMap.scala:32)\r\n\tat org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:194)\r\n\tat org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:62)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:121)\r\n\tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:402)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:408)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n\tat java.lang.Thread.run(Thread.java:748)\r\n\nDriver stacktrace:\r\n\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1887)\r\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1875)\r\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1874)\r\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\r\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\r\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1874)\r\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)\r\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)\r\n\tat scala.Option.foreach(Option.scala:257)\r\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:926)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2108)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2057)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2046)\r\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\r\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:737)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2061)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2082)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2101)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2126)\r\n\tat org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:945)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\r\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:363)\r\n\tat org.apache.spark.rdd.RDD.collect(RDD.scala:944)\r\n\tat org.apache.spark.ml.classification.NaiveBayes$$anonfun$trainWithLabelCheck$1.apply(NaiveBayes.scala:176)\r\n\tat org.apache.spark.ml.classification.NaiveBayes$$anonfun$trainWithLabelCheck$1.apply(NaiveBayes.scala:129)\r\n\tat org.apache.spark.ml.util.Instrumentation$$anonfun$11.apply(Instrumentation.scala:183)\r\n\tat scala.util.Try$.apply(Try.scala:192)\r\n\tat org.apache.spark.ml.util.Instrumentation$.instrumented(Instrumentation.scala:183)\r\n\tat org.apache.spark.ml.classification.NaiveBayes.trainWithLabelCheck(NaiveBayes.scala:129)\r\n\tat org.apache.spark.ml.classification.NaiveBayes.train(NaiveBayes.scala:118)\r\n\tat org.apache.spark.ml.classification.NaiveBayes.train(NaiveBayes.scala:78)\r\n\tat org.apache.spark.ml.Predictor.fit(Predictor.scala:118)\r\n\tat sun.reflect.GeneratedMethodAccessor336.invoke(Unknown Source)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.lang.reflect.Method.invoke(Method.java:498)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\r\n\tat java.lang.Thread.run(Thread.java:748)\r\nCaused by: java.lang.IllegalArgumentException: requirement failed: Naive Bayes requires nonnegative feature values but found [-0.012262186447185451,0.22753394624906714,-0.028704270666492157].\r\n\tat scala.Predef$.require(Predef.scala:224)\r\n\tat org.apache.spark.ml.classification.NaiveBayes$.requireNonnegativeValues(NaiveBayes.scala:235)\r\n\tat org.apache.spark.ml.classification.NaiveBayes$$anonfun$trainWithLabelCheck$1$$anonfun$4.apply(NaiveBayes.scala:144)\r\n\tat org.apache.spark.ml.classification.NaiveBayes$$anonfun$trainWithLabelCheck$1$$anonfun$4.apply(NaiveBayes.scala:144)\r\n\tat org.apache.spark.ml.classification.NaiveBayes$$anonfun$trainWithLabelCheck$1$$anonfun$7.apply(NaiveBayes.scala:168)\r\n\tat org.apache.spark.ml.classification.NaiveBayes$$anonfun$trainWithLabelCheck$1$$anonfun$7.apply(NaiveBayes.scala:166)\r\n\tat org.apache.spark.util.collection.ExternalSorter$$anonfun$5.apply(ExternalSorter.scala:189)\r\n\tat org.apache.spark.util.collection.ExternalSorter$$anonfun$5.apply(ExternalSorter.scala:188)\r\n\tat org.apache.spark.util.collection.AppendOnlyMap.changeValue(AppendOnlyMap.scala:150)\r\n\tat org.apache.spark.util.collection.SizeTrackingAppendOnlyMap.changeValue(SizeTrackingAppendOnlyMap.scala:32)\r\n\tat org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:194)\r\n\tat org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:62)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:121)\r\n\tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:402)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:408)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n\t... 1 more\r\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-68-b447b9eb8a5a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mnb_w2v\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNaiveBayes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msmoothing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mmodel_w2v\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnb_w2v\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset_w2v\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mpredictions_w2v\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_w2v\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_dataset_w2v\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mpredictions_w2v\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlabelConverter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredictions_w2v\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# Transform labels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\spark\\spark-2.4.0-bin-hadoop2.7\\python\\pyspark\\ml\\base.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, dataset, params)\u001b[0m\n\u001b[0;32m    130\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    131\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 132\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    133\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    134\u001b[0m             raise ValueError(\"Params must be either a param map or a list/tuple of param maps, \"\n",
      "\u001b[1;32m~\\Desktop\\spark\\spark-2.4.0-bin-hadoop2.7\\python\\pyspark\\ml\\wrapper.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, dataset)\u001b[0m\n\u001b[0;32m    293\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    294\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 295\u001b[1;33m         \u001b[0mjava_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit_java\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    296\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjava_model\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    297\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_copyValues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\spark\\spark-2.4.0-bin-hadoop2.7\\python\\pyspark\\ml\\wrapper.py\u001b[0m in \u001b[0;36m_fit_java\u001b[1;34m(self, dataset)\u001b[0m\n\u001b[0;32m    290\u001b[0m         \"\"\"\n\u001b[0;32m    291\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_transfer_params_to_java\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 292\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_java_obj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    293\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    294\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\spark\\spark-2.4.0-bin-hadoop2.7\\python\\lib\\py4j-0.10.7-src.zip\\py4j\\java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1255\u001b[0m         \u001b[0manswer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[1;32m-> 1257\u001b[1;33m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[0;32m   1258\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1259\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\spark\\spark-2.4.0-bin-hadoop2.7\\python\\pyspark\\sql\\utils.py\u001b[0m in \u001b[0;36mdeco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m     61\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoString\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\spark\\spark-2.4.0-bin-hadoop2.7\\python\\lib\\py4j-0.10.7-src.zip\\py4j\\protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[1;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[0;32m    326\u001b[0m                 raise Py4JJavaError(\n\u001b[0;32m    327\u001b[0m                     \u001b[1;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 328\u001b[1;33m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[0;32m    329\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    330\u001b[0m                 raise Py4JError(\n",
      "\u001b[1;31mPy4JJavaError\u001b[0m: An error occurred while calling o134276.fit.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 22972.0 failed 1 times, most recent failure: Lost task 0.0 in stage 22972.0 (TID 23568, localhost, executor driver): java.lang.IllegalArgumentException: requirement failed: Naive Bayes requires nonnegative feature values but found [-0.012262186447185451,0.22753394624906714,-0.028704270666492157].\r\n\tat scala.Predef$.require(Predef.scala:224)\r\n\tat org.apache.spark.ml.classification.NaiveBayes$.requireNonnegativeValues(NaiveBayes.scala:235)\r\n\tat org.apache.spark.ml.classification.NaiveBayes$$anonfun$trainWithLabelCheck$1$$anonfun$4.apply(NaiveBayes.scala:144)\r\n\tat org.apache.spark.ml.classification.NaiveBayes$$anonfun$trainWithLabelCheck$1$$anonfun$4.apply(NaiveBayes.scala:144)\r\n\tat org.apache.spark.ml.classification.NaiveBayes$$anonfun$trainWithLabelCheck$1$$anonfun$7.apply(NaiveBayes.scala:168)\r\n\tat org.apache.spark.ml.classification.NaiveBayes$$anonfun$trainWithLabelCheck$1$$anonfun$7.apply(NaiveBayes.scala:166)\r\n\tat org.apache.spark.util.collection.ExternalSorter$$anonfun$5.apply(ExternalSorter.scala:189)\r\n\tat org.apache.spark.util.collection.ExternalSorter$$anonfun$5.apply(ExternalSorter.scala:188)\r\n\tat org.apache.spark.util.collection.AppendOnlyMap.changeValue(AppendOnlyMap.scala:150)\r\n\tat org.apache.spark.util.collection.SizeTrackingAppendOnlyMap.changeValue(SizeTrackingAppendOnlyMap.scala:32)\r\n\tat org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:194)\r\n\tat org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:62)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:121)\r\n\tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:402)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:408)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n\tat java.lang.Thread.run(Thread.java:748)\r\n\nDriver stacktrace:\r\n\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1887)\r\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1875)\r\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1874)\r\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\r\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\r\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1874)\r\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)\r\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)\r\n\tat scala.Option.foreach(Option.scala:257)\r\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:926)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2108)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2057)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2046)\r\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\r\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:737)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2061)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2082)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2101)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2126)\r\n\tat org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:945)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\r\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:363)\r\n\tat org.apache.spark.rdd.RDD.collect(RDD.scala:944)\r\n\tat org.apache.spark.ml.classification.NaiveBayes$$anonfun$trainWithLabelCheck$1.apply(NaiveBayes.scala:176)\r\n\tat org.apache.spark.ml.classification.NaiveBayes$$anonfun$trainWithLabelCheck$1.apply(NaiveBayes.scala:129)\r\n\tat org.apache.spark.ml.util.Instrumentation$$anonfun$11.apply(Instrumentation.scala:183)\r\n\tat scala.util.Try$.apply(Try.scala:192)\r\n\tat org.apache.spark.ml.util.Instrumentation$.instrumented(Instrumentation.scala:183)\r\n\tat org.apache.spark.ml.classification.NaiveBayes.trainWithLabelCheck(NaiveBayes.scala:129)\r\n\tat org.apache.spark.ml.classification.NaiveBayes.train(NaiveBayes.scala:118)\r\n\tat org.apache.spark.ml.classification.NaiveBayes.train(NaiveBayes.scala:78)\r\n\tat org.apache.spark.ml.Predictor.fit(Predictor.scala:118)\r\n\tat sun.reflect.GeneratedMethodAccessor336.invoke(Unknown Source)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.lang.reflect.Method.invoke(Method.java:498)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\r\n\tat java.lang.Thread.run(Thread.java:748)\r\nCaused by: java.lang.IllegalArgumentException: requirement failed: Naive Bayes requires nonnegative feature values but found [-0.012262186447185451,0.22753394624906714,-0.028704270666492157].\r\n\tat scala.Predef$.require(Predef.scala:224)\r\n\tat org.apache.spark.ml.classification.NaiveBayes$.requireNonnegativeValues(NaiveBayes.scala:235)\r\n\tat org.apache.spark.ml.classification.NaiveBayes$$anonfun$trainWithLabelCheck$1$$anonfun$4.apply(NaiveBayes.scala:144)\r\n\tat org.apache.spark.ml.classification.NaiveBayes$$anonfun$trainWithLabelCheck$1$$anonfun$4.apply(NaiveBayes.scala:144)\r\n\tat org.apache.spark.ml.classification.NaiveBayes$$anonfun$trainWithLabelCheck$1$$anonfun$7.apply(NaiveBayes.scala:168)\r\n\tat org.apache.spark.ml.classification.NaiveBayes$$anonfun$trainWithLabelCheck$1$$anonfun$7.apply(NaiveBayes.scala:166)\r\n\tat org.apache.spark.util.collection.ExternalSorter$$anonfun$5.apply(ExternalSorter.scala:189)\r\n\tat org.apache.spark.util.collection.ExternalSorter$$anonfun$5.apply(ExternalSorter.scala:188)\r\n\tat org.apache.spark.util.collection.AppendOnlyMap.changeValue(AppendOnlyMap.scala:150)\r\n\tat org.apache.spark.util.collection.SizeTrackingAppendOnlyMap.changeValue(SizeTrackingAppendOnlyMap.scala:32)\r\n\tat org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:194)\r\n\tat org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:62)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:121)\r\n\tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:402)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:408)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n\t... 1 more\r\n"
     ]
    }
   ],
   "source": [
    "nb_w2v = NaiveBayes(smoothing=1)\n",
    "\n",
    "model_w2v = nb_w2v.fit(dataset_w2v)\n",
    "predictions_w2v = model_w2v.transform(test_dataset_w2v)\n",
    "predictions_w2v = labelConverter.transform(predictions_w2v) # Transform labels\n",
    "\n",
    "predictions_w2v.filter(predictions_w2v['prediction'] == 0) \\\n",
    "    .select(\"text\",\"probability\",\"review_score\",\"predictedScore\") \\\n",
    "    .orderBy(\"probability\", ascending=False) \\\n",
    "    .show(n = 10, truncate = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "evaluator_w2v = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "evaluator_w2v.evaluate(predictions_w2v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Random Forest Word2Vec</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------+------------------------------+------------+--------------+\n",
      "|                          text|                   probability|review_score|predictedScore|\n",
      "+------------------------------+------------------------------+------------+--------------+\n",
      "|Lies My Doctor Told Me Seco...|[0.851404883414099,0.095432...|           5|             5|\n",
      "|Lies My Doctor Told Me Seco...|[0.851404883414099,0.095432...|           5|             5|\n",
      "|Lies My Doctor Told Me Seco...|[0.851265785631412,0.095919...|           4|             5|\n",
      "|Lies My Doctor Told Me Seco...|[0.851265785631412,0.095919...|           5|             5|\n",
      "|Lies My Doctor Told Me Seco...|[0.851265785631412,0.095919...|           5|             5|\n",
      "|Lies My Doctor Told Me Seco...|[0.851265785631412,0.095919...|           5|             5|\n",
      "|Lies My Doctor Told Me Seco...|[0.8510519422376285,0.09554...|           5|             5|\n",
      "|Lies My Doctor Told Me Seco...|[0.8510519422376285,0.09554...|           5|             5|\n",
      "|Lies My Doctor Told Me Seco...|[0.8510519422376285,0.09554...|           5|             5|\n",
      "|Lies My Doctor Told Me Seco...|[0.8510519422376285,0.09554...|           5|             5|\n",
      "+------------------------------+------------------------------+------------+--------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf_w2v = RandomForestClassifier(labelCol=\"label\", \\\n",
    "                            featuresCol=\"features\", \\\n",
    "                            numTrees = 100, \\\n",
    "                            maxDepth = 4, \\\n",
    "                            maxBins = 32)\n",
    "\n",
    "# Train model with Training Data\n",
    "rfModel_w2v = rf_w2v.fit(dataset_w2v)\n",
    "predictions_w2v = rfModel_w2v.transform(test_dataset_w2v)\n",
    "predictions_w2v = labelConverter.transform(predictions_w2v) # Transform labels\n",
    "\n",
    "predictions_w2v.filter(predictions_w2v['prediction'] == 0) \\\n",
    "    .select(\"text\",\"probability\",\"review_score\",\"predictedScore\") \\\n",
    "    .orderBy(\"probability\", ascending=False) \\\n",
    "    .show(n = 10, truncate = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6729005535062502"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator_w2v = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "evaluator_w2v.evaluate(predictions_w2v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Crossvalidation </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6807749530095831"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_w2v = RandomForestClassifier(labelCol=\"label\", \\\n",
    "                            featuresCol=\"features\", \\\n",
    "                            numTrees = 100, \\\n",
    "                            maxDepth = 4)\n",
    "\n",
    "# Create ParamGrid for Cross Validation\n",
    "paramGrid = (ParamGridBuilder()\n",
    "             .addGrid(rf_w2v.numTrees, [100, 200, 500]) # regularization parameter\n",
    "             .addGrid(rf_w2v.maxDepth, [4, 10, 20]) # Elastic Net Parameter (Ridge = 0)\n",
    "#            .addGrid(model.maxIter, [10, 20, 50]) #Number of iterations\n",
    "#            .addGrid(idf.numFeatures, [10, 100, 1000]) # Number of features\n",
    "             .build())\n",
    "\n",
    "# Create 5-fold CrossValidator\n",
    "cv_w2v = CrossValidator(estimator=rf_w2v, \\\n",
    "                    estimatorParamMaps=paramGrid, \\\n",
    "                    evaluator=evaluator, \\\n",
    "                    numFolds=5)\n",
    "\n",
    "cvModel_w2v = cv_w2v.fit(dataset_w2v)\n",
    "\n",
    "predictions_w2v = cvModel_w2v.transform(test_dataset_w2v)\n",
    "predictions_w2v = labelConverter.transform(predictions_w2v) # Transform labels\n",
    "\n",
    "# Evaluate best model\n",
    "evaluator_w2v = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "evaluator_w2v.evaluate(predictions_w2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassificationModel (uid=RandomForestClassifier_340b41819664) with 200 trees"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model_w2v = cvModel_w2v.bestModel\n",
    "best_model_w2v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "best_numTrees_w2v = best_model_w2v.getNumTrees\n",
    "best_maxDepth_w2v = best_model_w2v.getOrDefault('maxDepth')\n",
    "print(best_numTrees_w2v);print(best_maxDepth_w2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------+------------------------------+------------+--------------+\n",
      "|                          text|                   probability|review_score|predictedScore|\n",
      "+------------------------------+------------------------------+------------+--------------+\n",
      "|The Mueller Report Trump Su...|[0.9690421658765567,0.02146...|           5|             5|\n",
      "|A Gentleman in Moscow: A No...|[0.9675726079180089,0.02606...|           5|             5|\n",
      "|The Longevity Solution: Red...|[0.967295200535754,0.021602...|           5|             5|\n",
      "|Clean & Lean: 30 Days, 30 F...|[0.9652177755134765,0.02572...|           5|             5|\n",
      "|Lies My Doctor Told Me Seco...|[0.9646743305732678,0.02642...|           5|             5|\n",
      "|Lies My Doctor Told Me Seco...|[0.9646743305732678,0.02642...|           5|             5|\n",
      "|QAnon: An Invitation to The...|[0.9644163712868223,0.02289...|           5|             5|\n",
      "|Lies My Doctor Told Me Seco...|[0.9639520820527009,0.02516...|           5|             5|\n",
      "|Lies My Doctor Told Me Seco...|[0.9639520820527009,0.02516...|           5|             5|\n",
      "|Free to Focus: A Total Prod...|[0.9637558454882532,0.02290...|           5|             5|\n",
      "+------------------------------+------------------------------+------------+--------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions_w2v.filter(predictions_w2v['prediction'] == 0) \\\n",
    "    .select(\"text\",\"probability\",\"review_score\",\"predictedScore\") \\\n",
    "    .orderBy(\"probability\", ascending=False) \\\n",
    "    .show(n = 10, truncate = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(review_score=1, text=\"A Gentleman in Moscow: A Novel Too slow This has to be one of the most boring books I've read.  It takes chapters upon chapters to move the story forward.  I stopped reading after then seventh chapter\", words=['a', 'gentleman', 'in', 'moscow', 'a', 'novel', 'too', 'slow', 'this', 'has', 'to', 'be', 'one', 'of', 'the', 'most', 'boring', 'books', 'i', 've', 'read', 'it', 'takes', 'chapters', 'upon', 'chapters', 'to', 'move', 'the', 'story', 'forward', 'i', 'stopped', 'reading', 'after', 'then', 'seventh', 'chapter'], filtered=['gentleman', 'moscow', 'novel', 'slow', 'one', 'boring', 'books', 'read', 'takes', 'chapters', 'upon', 'chapters', 'move', 'story', 'forward', 'stopped', 'reading', 'seventh', 'chapter'], features=DenseVector([0.0249, 0.4134, 0.066]), label=4.0, rawPrediction=DenseVector([139.1004, 37.6634, 16.2856, 3.5282, 3.4224]), probability=DenseVector([0.6955, 0.1883, 0.0814, 0.0176, 0.0171]), prediction=0.0, predictedScore='5')]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_w2v.head(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 122.66666599999999,
   "position": {
    "height": "144px",
    "left": "1009px",
    "right": "20px",
    "top": "120px",
    "width": "250px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "block",
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
