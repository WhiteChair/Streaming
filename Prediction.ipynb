{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:95% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from threading import Thread\n",
    "\n",
    "class StreamingThread(Thread):\n",
    "    def __init__(self, ssc):\n",
    "        Thread.__init__(self)\n",
    "        self.ssc = ssc\n",
    "    def run(self):\n",
    "        ssc.start()\n",
    "        ssc.awaitTermination()\n",
    "    def stop(self):\n",
    "        print('----- Stopping... this may take a few seconds -----')\n",
    "        self.ssc.stop(stopSparkContext=False, stopGraceFully=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://LAPTOP-DIEK95KA:4045\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[*] appName=PySparkShell>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://LAPTOP-DIEK95KA:4045\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x158cbaeccf8>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.streaming import StreamingContext\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql.functions import udf, struct\n",
    "from pyspark.sql.types import IntegerType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as ff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline, PipelineModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "globals()['models_loaded'] = False\n",
    "\n",
    "#def predict(df):\n",
    "    # Replace this with something smarter\n",
    "#    if any([x in df.review_text for x in ['not', 'bad', 'terrible', 'zero', 'one']]):\n",
    "#        return 1\n",
    "#    return 5\n",
    "\n",
    "#predict_udf = udf(predict, IntegerType())\n",
    "\n",
    "def process(time, rdd):\n",
    "    if rdd.isEmpty():\n",
    "        return\n",
    "    print(\"========= %s =========\" % str(time))\n",
    "    \n",
    "    # Convert to data frame\n",
    "    df = spark.read.json(rdd)\n",
    "    df.show()\n",
    "    \n",
    "    df_withpreds = df.withColumn('text', ff.concat(ff.col('review_title'), ff.lit(' '), ff.col('review_text'))) #removed book_title\n",
    "    \n",
    "    drop_list = ['book_title', 'review_title', 'review_user', 'book_id', 'review_id', \n",
    "             'timestamp', 'review_text']\n",
    "    df_withpreds = df_withpreds.select([column for column in df_withpreds.columns if column not in drop_list])\n",
    "    #df_withpreds.show()\n",
    "    \n",
    "    # Utilize our predict function\n",
    "    #df_withpreds = df.withColumn(\"pred\", predict_udf(struct([df[x] for x in df.columns])))\n",
    "    #df_withpreds.show()\n",
    "    \n",
    "    # Normally, you wouldn't use a Python function to predict\n",
    "    # But an MLlib model you've built and saved with Spark\n",
    "    \n",
    "    # In this case, you need to prevent loading your model in every call to \"process\" as follows:\n",
    "    \n",
    "    # Load in the model if not yet loaded:\n",
    "    if not globals()['models_loaded']:\n",
    "        # load in your models here\n",
    "        globals()['my_model'] = PipelineModel.load('pipeline_nb') # Replace this with:    [...].load('my_logistic_regression')\n",
    "        globals()['models_loaded'] = True\n",
    "        \n",
    "    # Predict using the model: \n",
    "    df_result = globals()['my_model'].transform(df_withpreds)\n",
    "    #drop_list2 = ['words', 'filtered', 'rawFeatures', 'features', 'label', \n",
    "    #         'rawPrediction', 'prediction']\n",
    "    #df_result = df_result.select([column for column in df_result.columns if column not in drop_list2])\n",
    "    \n",
    "    df_result = df_result.select(\"text\",\"probability\",\"review_score\",\"predictedScore\")\n",
    "    df_result.show()\n",
    "    #df_result = globals()['my_model'].transform(df)\n",
    "    #df_result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssc = StreamingContext(sc, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = ssc.socketTextStream(\"seppe.net\", 7778)\n",
    "lines.foreachRDD(process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========= 2019-06-01 17:06:00 =========\n",
      "+----------+--------------------+--------------+------------+--------------------+--------------------+-----------+----------+\n",
      "|   book_id|          book_title|     review_id|review_score|         review_text|        review_title|review_user| timestamp|\n",
      "+----------+--------------------+--------------+------------+--------------------+--------------------+-----------+----------+\n",
      "|1476773092|Unfreedom of the ...|R3I34CXTG21TUO|           5|While I felt the ...|Compelling, well-...|Serenity...|1559401129|\n",
      "+----------+--------------------+--------------+------------+--------------------+--------------------+-----------+----------+\n",
      "\n",
      "+--------------------+--------------------+------------+--------------+\n",
      "|                text|         probability|review_score|predictedScore|\n",
      "+--------------------+--------------------+------------+--------------+\n",
      "|Compelling, well-...|[0.01015436416008...|           5|             4|\n",
      "+--------------------+--------------------+------------+--------------+\n",
      "\n",
      "========= 2019-06-01 17:06:10 =========\n",
      "+----------+----------+--------------+------------+--------------------+--------------------+-----------+----------+\n",
      "|   book_id|book_title|     review_id|review_score|         review_text|        review_title|review_user| timestamp|\n",
      "+----------+----------+--------------+------------+--------------------+--------------------+-----------+----------+\n",
      "|1982102314| Elevation|R3RUID0902R1HO|           5|Not novel length ...|Read more like a ...| R. Vincent|1559401203|\n",
      "+----------+----------+--------------+------------+--------------------+--------------------+-----------+----------+\n",
      "\n",
      "+--------------------+--------------------+------------+--------------+\n",
      "|                text|         probability|review_score|predictedScore|\n",
      "+--------------------+--------------------+------------+--------------+\n",
      "|Read more like a ...|[0.54881414105358...|           5|             5|\n",
      "+--------------------+--------------------+------------+--------------+\n",
      "\n",
      "========= 2019-06-01 17:06:20 =========\n",
      "+----------+--------------------+--------------+------------+--------------------+------------+-----------+----------+\n",
      "|   book_id|          book_title|     review_id|review_score|         review_text|review_title|review_user| timestamp|\n",
      "+----------+--------------------+--------------+------------+--------------------+------------+-----------+----------+\n",
      "|198211598X|Pet Sematary: A N...|R1WCOGDKU0Q8UG|           5|Before I picked u...|     Redrum!| Blindguy07|1559401263|\n",
      "+----------+--------------------+--------------+------------+--------------------+------------+-----------+----------+\n",
      "\n",
      "+--------------------+--------------------+------------+--------------+\n",
      "|                text|         probability|review_score|predictedScore|\n",
      "+--------------------+--------------------+------------+--------------+\n",
      "|Redrum! Before I ...|[0.79672679202596...|           5|             5|\n",
      "+--------------------+--------------------+------------+--------------+\n",
      "\n",
      "========= 2019-06-01 17:06:30 =========\n",
      "+---------+--------------------+--------------+------------+--------------------+--------------------+-----------+----------+\n",
      "|  book_id|          book_title|     review_id|review_score|         review_text|        review_title|review_user| timestamp|\n",
      "+---------+--------------------+--------------+------------+--------------------+--------------------+-----------+----------+\n",
      "|847864146|Pacific Natural: ...|R2UR0HOWL69QMI|           5|this book is so p...|simple entertaini...|       Anne|1559401369|\n",
      "+---------+--------------------+--------------+------------+--------------------+--------------------+-----------+----------+\n",
      "\n",
      "+--------------------+--------------------+------------+--------------+\n",
      "|                text|         probability|review_score|predictedScore|\n",
      "+--------------------+--------------------+------------+--------------+\n",
      "|simple entertaini...|[0.97524517386857...|           5|             5|\n",
      "+--------------------+--------------------+------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ssc_t = StreamingThread(ssc)\n",
    "ssc_t.start()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "ssc_t.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
