{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Data preprocessing</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SQLContext\n",
    "\n",
    "sqlContext = SQLContext(sc)\n",
    "data = sqlContext.read.format('com.databricks.spark.csv').options(header='true', \n",
    "                                                                  inferschema='true', \n",
    "                                                                  quote = '\"', \n",
    "                                                                  escape = '\"',\n",
    "                                                                 multiline = 'true',\n",
    "                                                                 ignoreTrailingWhiteSpace = 'true').load('Data/data.csv')\n",
    "\n",
    "# There were some problems reading the data, here I found the solutions\n",
    "# https://stackoverflow.com/questions/40413526/reading-csv-files-with-quoted-fields-containing-embedded-commas\n",
    "#https://stackoverflow.com/questions/50477857/spark-fails-to-read-csv-when-last-column-name-contains-spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read data frame in pandas\n",
    "\n",
    "import pandas as pd\n",
    "odf = pd.read_csv('/Users/Gianina/Documents/MSc/spark/notebooks/data.csv', encoding = 'unicode_escape')\n",
    "odf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge review title and text into a single column in pandas\n",
    "odf['text'] = odf.agg('{0[review_title]}  {0[review_text]}'.format, axis=1)\n",
    "odf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+--------------------+--------------+----------+--------------+----------+--------------------+------------+\n",
      "|  X|          book_title|        review_title|   review_user|   book_id|     review_id| timestamp|         review_text|review_score|\n",
      "+---+--------------------+--------------------+--------------+----------+--------------+----------+--------------------+------------+\n",
      "|  1|A Gentleman in Mo...|Russian aristocra...|    Kansabelle|0143110438|R2UFCQ9WES7VFH|1555241537|A great read. In ...|           4|\n",
      "|  2|A Gentleman in Mo...|Knowing nothing a...|  D.P. McHenry|0143110438|R24B1HA9J9I99G|1555241542|Great story, well...|           4|\n",
      "|  3|Pet Sematary: A N...|One of King's fin...|Gordon Hoffman|198211598X|R1P137WFADSBYR|1555241649|Only the second n...|           4|\n",
      "|  4|Less (Winner of t...|     Not my favorite|     R. Zocher|0316316121|R35533AKR5CBNS|1555242044|This book is t wh...|           4|\n",
      "|  5|         Supermarket|      AMAZING, BOBBY|    D. Mahoney|1982127139|R1D6LXSDR0CRMN|1555242169|As someone who ha...|           4|\n",
      "+---+--------------------+--------------------+--------------+----------+--------------+----------+--------------------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#drop_list = ['Dates', 'DayOfWeek', 'PdDistrict', 'Resolution', 'Address', 'X', 'Y']\n",
    "#data = data.select([column for column in data.columns if column not in drop_list])\n",
    "data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- X: integer (nullable = true)\n",
      " |-- book_title: string (nullable = true)\n",
      " |-- review_title: string (nullable = true)\n",
      " |-- review_user: string (nullable = true)\n",
      " |-- book_id: string (nullable = true)\n",
      " |-- review_id: string (nullable = true)\n",
      " |-- timestamp: integer (nullable = true)\n",
      " |-- review_text: string (nullable = true)\n",
      " |-- review_score: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----+\n",
      "|review_score|count|\n",
      "+------------+-----+\n",
      "|           5| 3236|\n",
      "|           4|  598|\n",
      "|           3|  187|\n",
      "|           1|  110|\n",
      "|           2|  108|\n",
      "+------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "data.groupBy(\"review_score\") \\\n",
    "    .count() \\\n",
    "    .orderBy(col(\"count\").desc()) \\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4239"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------------+--------------------+-----------+----------+--------------+----------+-----------+------------+\n",
      "|   X|          book_title|        review_title|review_user|   book_id|     review_id| timestamp|review_text|review_score|\n",
      "+----+--------------------+--------------------+-----------+----------+--------------+----------+-----------+------------+\n",
      "|1121|Lies My Doctor To...|This book gave a ...|   mawshell|162860378X|R3SIH2LVO3EYMH|1555252626|       null|           5|\n",
      "+----+--------------------+--------------------+-----------+----------+--------------+----------+-----------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#data.filter(\"review_score is NULL\").show() # No nulls anymore\n",
    "#data.filter(\"X is NULL\").show() \n",
    "#data.filter(\"book_title is NULL\").show()\n",
    "#data.filter(\"review_title is NULL\").show()\n",
    "#data.filter(\"review_user is NULL\").show()\n",
    "#data.filter(\"book_id is NULL\").show()\n",
    "#data.filter(\"review_id is NULL\").show()\n",
    "#data.filter(\"timestamp is NULL\").show()\n",
    "data.filter(\"review_text is NULL\").show() # There is one null\n",
    "#data.filter(\"review_score is NULL\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove observation where review_text is null\n",
    "data = data.na.drop(subset=[\"review_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4238"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.count() # Removed!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------------------------------+----------------------------------------------------+-----------+----------+--------------+----------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|X  |book_title                    |review_title                                        |review_user|book_id   |review_id     |timestamp |review_text                                                                                                                                                                                                                        |review_score|text                                                                                                                                                                                                                                                                                    |\n",
      "+---+------------------------------+----------------------------------------------------+-----------+----------+--------------+----------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|1  |A Gentleman in Moscow: A Novel|Russian aristocracy following the Russian Revolution|Kansabelle |0143110438|R2UFCQ9WES7VFH|1555241537|A great read. In addition to the plot, characters, hidden treasure etc. I enjoyed the philosophical question: do Russians destroy more of what they create more than other cultures? Even if you stick to the characters-great fun.|4           |Russian aristocracy following the Russian Revolution A great read. In addition to the plot, characters, hidden treasure etc. I enjoyed the philosophical question: do Russians destroy more of what they create more than other cultures? Even if you stick to the characters-great fun.|\n",
      "+---+------------------------------+----------------------------------------------------+-----------+----------+--------------+----------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Concatenate book_title, review_title and review_text into a single column\n",
    "from pyspark.sql import functions as ff\n",
    "data = data.withColumn('text', ff.concat(ff.col('review_title'), ff.lit(' '), ff.col('review_text'))) #removed book_title\n",
    "data.show(1, truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------------------+\n",
      "|review_score|                text|\n",
      "+------------+--------------------+\n",
      "|           4|Russian aristocra...|\n",
      "|           4|Knowing nothing a...|\n",
      "|           4|One of King's fin...|\n",
      "|           4|Not my favorite T...|\n",
      "|           4|AMAZING, BOBBY As...|\n",
      "|           4|A really fun read...|\n",
      "|           4|So truly enjoyabl...|\n",
      "|           4|Well written and ...|\n",
      "|           3|Not one of his be...|\n",
      "|           4|Beautiful It's no...|\n",
      "|           4|The last returns ...|\n",
      "|           4|Don't open this b...|\n",
      "|           4|Bobby Bestseller!...|\n",
      "|           4|Listen to this in...|\n",
      "|           4|A book with a mes...|\n",
      "|           4|Glad I read this ...|\n",
      "|           4|Gentleman From Mo...|\n",
      "|           4|It is a terrific ...|\n",
      "|           2|An OK read if the...|\n",
      "|           4|Just as scary now...|\n",
      "+------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "drop_list = ['X', 'book_title', 'review_title', 'review_user', 'book_id', 'review_id', \n",
    "             'timestamp', 'review_text']\n",
    "data = data.select([column for column in data.columns if column not in drop_list])\n",
    "data.show(20, )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Now the modelling pipeline starts</h3>\n",
    "I got it from: https://towardsdatascience.com/multi-class-text-classification-with-pyspark-7d78d022ed35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import RegexTokenizer, StopWordsRemover, CountVectorizer\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "import nltk\n",
    "#nltk.download(\"stopwords\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataset Count: 3333\n",
      "Test Dataset Count: 905\n"
     ]
    }
   ],
   "source": [
    "# set seed for reproducibility\n",
    "(trainingData, testData) = data.randomSplit([0.8, 0.2], seed = 12345)\n",
    "print(\"Training Dataset Count: \" + str(trainingData.count()))\n",
    "print(\"Test Dataset Count: \" + str(testData.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regular expression tokenizer: To split sentences into words\n",
    "regexTokenizer = RegexTokenizer(inputCol=\"text\", outputCol=\"words\", pattern=\"\\\\W\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stop words\n",
    "stopwordList = nltk.corpus.stopwords.words('english')\n",
    "stopwordsRemover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered\", stopWords=stopwordList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Juliana\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bag of words count\n",
    "countVectors = CountVectorizer(inputCol=\"filtered\", outputCol=\"features\", vocabSize=20000, minDF=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer, VectorAssembler\n",
    "\n",
    "# Recoding target variable\n",
    "label_stringIdx = StringIndexer(inputCol = \"review_score\", outputCol = \"label\") \n",
    "labels_stars = label_stringIdx.fit(trainingData).labels # Save this levels to be able later to transform back\n",
    "\n",
    "# Create pipeline\n",
    "pipeline = Pipeline(stages=[regexTokenizer, stopwordsRemover, countVectors, label_stringIdx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------------------+--------------------+--------------------+--------------------+-----+\n",
      "|review_score|                text|               words|            filtered|            features|label|\n",
      "+------------+--------------------+--------------------+--------------------+--------------------+-----+\n",
      "|           1|*Eye roll* I firs...|[eye, roll, i, fi...|[eye, roll, first...|(415,[0,2,3,4,6,9...|  4.0|\n",
      "|           1|1 of the normal H...|[1, of, the, norm...|[1, normal, start...|(415,[0,16,32,42,...|  4.0|\n",
      "|           1|580 pages to just...|[580, pages, to, ...|[580, pages, quit...|(415,[0,1,2,3,4,5...|  4.0|\n",
      "|           1|A political hit j...|[a, political, hi...|[political, hit, ...|(415,[0,22,54,227...|  4.0|\n",
      "|           1|Amazing Read but ...|[amazing, read, b...|[amazing, read, d...|(415,[0,1,12,25,5...|  4.0|\n",
      "+------------+--------------------+--------------------+--------------------+--------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Fit the pipeline to training data.\n",
    "pipelineFit = pipeline.fit(trainingData)\n",
    "dataset = pipelineFit.transform(trainingData)\n",
    "#dataset.show(1, truncate = False)\n",
    "dataset.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------------------+--------------------+--------------------+--------------------+-----+\n",
      "|review_score|                text|               words|            filtered|            features|label|\n",
      "+------------+--------------------+--------------------+--------------------+--------------------+-----+\n",
      "|           1|A waste of money ...|[a, waste, of, mo...|[waste, money, ti...|(415,[5,10,56,375...|  4.0|\n",
      "|           1|Attn AMAZON Kindl...|[attn, amazon, ki...|[attn, amazon, ki...|(415,[0,11,116,13...|  4.0|\n",
      "|           1|Baid and Switch I...|[baid, and, switc...|[baid, switch, ha...|(415,[21,23,138,2...|  4.0|\n",
      "|           1|Boring ! I'm a hu...|[boring, i, m, a,...|[boring, huge, fa...|(415,[2,22,144,30...|  4.0|\n",
      "|           1|Boring Great plot...|[boring, great, p...|[boring, great, p...|(415,[4,25,63,230...|  4.0|\n",
      "+------------+--------------------+--------------------+--------------------+--------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Fit the pipeline to test data.\n",
    "test_dataset = pipelineFit.transform(testData)\n",
    "#test_dataset.show(1, truncate = False)\n",
    "test_dataset.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original encoding\n",
    "trainingData.groupBy(\"review_score\") \\\n",
    "    .count() \\\n",
    "    .orderBy(col(\"count\").desc()) \\\n",
    "    .show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show how the encoding changed\n",
    "dataset.groupBy(\"label\") \\\n",
    "    .count() \\\n",
    "    .orderBy(col(\"count\").desc()) \\\n",
    "    .show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Logistic regression using count vector features</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import IndexToString\n",
    "\n",
    "# Transform back from index to original coding\n",
    "labelConverter = IndexToString(inputCol=\"prediction\", outputCol=\"predictedScore\", labels = labels_stars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------------------+---------------------------------------------+------------+--------------+\n",
      "|                                         text|                                  probability|review_score|predictedScore|\n",
      "+---------------------------------------------+---------------------------------------------+------------+--------------+\n",
      "|A masterpiece of theory from from a master...|[0.9999999999999991,7.954030889775193E-16,...|           4|             5|\n",
      "|A Mentally Ill Woman, Anna Fox, Witnesses ...|[0.9999999999996585,3.415128690030579E-13,...|           4|             5|\n",
      "|All Stiva, No Lev On the plus side, the no...|[0.9999999999981952,1.1338152616723868E-12...|           4|             5|\n",
      "|exceptional novel - one of the best this y...|[0.9999999999943094,5.690332398125168E-12,...|           5|             5|\n",
      "|Another blockbuster of a historical fictio...|[0.9999999851303771,1.4869556367930017E-8,...|           5|             5|\n",
      "|An engaging (exciting, even) memoir/master...|[0.9999999437499791,3.999597560976421E-8,7...|           5|             5|\n",
      "|Rachel Provides Easy Steps For Creating Ch...|[0.9999996821218458,3.15897100956149E-7,1....|           5|             5|\n",
      "|Bravo, Mr. Towles! After reading \"Rules of...|[0.9999994497352908,5.025798503924341E-7,4...|           5|             5|\n",
      "|Sometimes the price of justice is a good m...|[0.999999206324653,7.936753469304612E-7,7....|           5|             5|\n",
      "|A book with a message for today Growing up...|[0.9999986855974764,1.2894008377595997E-6,...|           4|             5|\n",
      "|Stop \"Dieting\" and Start Living If you are...|[0.9999983228836572,1.5942432237104852E-6,...|           5|             5|\n",
      "|A Must Read! Rich in detail and devastatin...|[0.9999982177613949,1.782238040773086E-6,2...|           5|             5|\n",
      "|A book that stays with you long after you ...|[0.9999981940259043,1.7862692384081904E-6,...|           5|             5|\n",
      "|... beyond five I would choose them endles...|[0.9999975485787979,2.440675650903981E-6,6...|           5|             5|\n",
      "|The best book you will ever read! By follo...|[0.9999958799197344,4.120034622132079E-6,4...|           5|             5|\n",
      "|Finally get to the root cause for female s...|[0.9999957722850747,4.227495921105216E-6,1...|           5|             5|\n",
      "|Beautifully written with elegant Beautiful...|[0.9999955071140441,4.486425082420969E-6,6...|           4|             5|\n",
      "|A fascinating world within a crazy world o...|[0.999991044503695,8.943530639099112E-6,1....|           5|             5|\n",
      "|One of the best books I have read this yea...|[0.9999894421315769,1.0557823991184138E-5,...|           5|             5|\n",
      "|Beautiful story, fascinating time and plac...|[0.9999893580184043,9.105458225896482E-6,1...|           5|             5|\n",
      "+---------------------------------------------+---------------------------------------------+------------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(maxIter=20, regParam=0, elasticNetParam=0)\n",
    "\n",
    "lrModel = lr.fit(dataset) # Fit model\n",
    "predictions = lrModel.transform(test_dataset) # Predict\n",
    "predictions = labelConverter.transform(predictions) # Transform labels\n",
    "\n",
    "predictions.filter(predictions['prediction'] == 0) \\\n",
    "    .select(\"text\",\"probability\",\"review_score\",\"predictedScore\") \\\n",
    "    .orderBy(\"probability\", ascending=False) \\\n",
    "    .show(n = 20, truncate = 45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7156069853194736"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "evaluator.evaluate(predictions) # This is the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(review_score=1, text='A waste of money and time Too long... too overly dramatic.  Narrator on audio needs to tone it down down down a few notches. Like waiting for paint to dry.', words=['a', 'waste', 'of', 'money', 'and', 'time', 'too', 'long', 'too', 'overly', 'dramatic', 'narrator', 'on', 'audio', 'needs', 'to', 'tone', 'it', 'down', 'down', 'down', 'a', 'few', 'notches', 'like', 'waiting', 'for', 'paint', 'to', 'dry'], filtered=['waste', 'money', 'time', 'long', 'overly', 'dramatic', 'narrator', 'audio', 'needs', 'tone', 'notches', 'like', 'waiting', 'paint', 'dry'], features=SparseVector(415, {5: 1.0, 10: 1.0, 56: 1.0, 375: 1.0, 395: 1.0}), label=4.0, rawPrediction=DenseVector([2.1111, -1.8611, -1.7852, -0.0291, 1.5643]), probability=DenseVector([0.5762, 0.0109, 0.0117, 0.0678, 0.3335]), prediction=0.0, predictedScore='5')]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Crossvalidation </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "\n",
    "lr = LogisticRegression(maxIter=20, regParam=0, elasticNetParam=0)\n",
    "\n",
    "# Create ParamGrid for Cross Validation\n",
    "paramGrid = (ParamGridBuilder()\n",
    "             .addGrid(lr.regParam, [0.01, 0.05, 0.1, 0.2, 0.3, 0.5]) # regularization parameter\n",
    "             .addGrid(lr.elasticNetParam, [0.0, 0.2, 0.4, 0.6, 0.8, 1]) # Elastic Net Parameter (Ridge = 0)\n",
    "#            .addGrid(model.maxIter, [10, 20, 50]) #Number of iterations\n",
    "#            .addGrid(idf.numFeatures, [10, 100, 1000]) # Number of features\n",
    "             .build())\n",
    "\n",
    "# Create 5-fold CrossValidator\n",
    "cv = CrossValidator(estimator=lr, \\\n",
    "                    estimatorParamMaps=paramGrid, \\\n",
    "                    evaluator=evaluator, \\\n",
    "                    numFolds=5)\n",
    "\n",
    "cvModel = cv.fit(dataset)\n",
    "\n",
    "predictions = cvModel.transform(test_dataset)\n",
    "predictions = labelConverter.transform(predictions) # Transform labels\n",
    "\n",
    "# Evaluate best model\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\", labelCol=\"label\")\n",
    "evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = cvModel.bestModel\n",
    "best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_reg_param = best_model._java_obj.getRegParam()\n",
    "best_elasticnet_param = best_model._java_obj.getElasticNetParam()\n",
    "print(best_reg_param);print(best_elasticnet_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.filter(predictions['prediction'] == 0) \\\n",
    "    .select(\"text\",\"probability\",\"review_score\",\"predictedScore\") \\\n",
    "    .orderBy(\"probability\", ascending=False) \\\n",
    "    .show(n = 20, truncate = 40)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "predictions.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To evaluate and get confusion matrix: https://runawayhorse001.github.io/LearningApacheSpark/classification.html\n",
    "#from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "#metrics = MulticlassMetrics(predictionCol=\"predictions\", labelCol=\"label\")\n",
    "#metrics.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Naive Bayes</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------------+----------------------------------------+------------+--------------+\n",
      "|                                    text|                             probability|review_score|predictedScore|\n",
      "+----------------------------------------+----------------------------------------+------------+--------------+\n",
      "|The best book you will ever read! By ...|[0.9999962814618197,3.503214632379414...|           5|             5|\n",
      "|What a POWERFUL story!! Unplanned is ...|[0.9999770160552786,2.298346047933018...|           5|             5|\n",
      "|Beautifully written with elegant Beau...|[0.9999733020487866,2.506506401722169...|           4|             5|\n",
      "|Amazing, beautiful, accessible book! ...|[0.9999701132582072,2.156537250510015...|           5|             5|\n",
      "|Bravo, Mr. Towles! After reading \"Rul...|[0.9999586010516772,1.892012273915955...|           5|             5|\n",
      "|exceptional novel - one of the best t...|[0.9999424971293328,5.642610535653649...|           5|             5|\n",
      "|Rachel Provides Easy Steps For Creati...|[0.999927561543873,6.0412625455744065...|           5|             5|\n",
      "|Anyone ready to change their life thr...|[0.9999228354249022,7.715097289559142...|           5|             5|\n",
      "|A Gentleman in Moscow is an hilarious...|[0.9999224662957438,7.75334640866308E...|           5|             5|\n",
      "|5 stars aren’t Enough! What an absolu...|[0.9999204340077175,7.88800311670668E...|           5|             5|\n",
      "|Stop \"Dieting\" and Start Living If yo...|[0.9999198680094615,4.532133271456414...|           5|             5|\n",
      "|Loved, loved, loved this book This wa...|[0.9999099451362912,8.737743412596169...|           5|             5|\n",
      "|A Must Read What a beautifully writte...|[0.9999054064150894,9.42491676323727E...|           5|             5|\n",
      "|Another beautifully written Amor Towl...|[0.9998515538658097,1.483637678109504...|           5|             5|\n",
      "|Learn why your doctor's advice is not...|[0.9998499745126727,7.974627081584794...|           5|             5|\n",
      "+----------------------------------------+----------------------------------------+------------+--------------+\n",
      "only showing top 15 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import NaiveBayes\n",
    "\n",
    "nb = NaiveBayes(smoothing=1)\n",
    "\n",
    "model = nb.fit(dataset)\n",
    "predictions = model.transform(test_dataset)\n",
    "predictions = labelConverter.transform(predictions) # Transform labels\n",
    "\n",
    "predictions.filter(predictions['prediction'] == 0) \\\n",
    "    .select(\"text\",\"probability\",\"review_score\",\"predictedScore\") \\\n",
    "    .orderBy(\"probability\", ascending=False) \\\n",
    "    .show(n = 15, truncate = 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7323989945784909"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_nb_final = Pipeline(stages=[regexTokenizer, stopwordsRemover, countVectors, label_stringIdx, nb, labelConverter])\n",
    "pipeline_nb_export = pipeline_nb_final.fit(trainingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export pipeline\n",
    "pipeline_nb_export.save('pipeline_nb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Random Forest</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(labelCol=\"label\", \\\n",
    "                            featuresCol=\"features\", \\\n",
    "                            numTrees = 100, \\\n",
    "                            maxDepth = 4, \\\n",
    "                            maxBins = 32)\n",
    "\n",
    "# Train model with Training Data\n",
    "rfModel = rf.fit(dataset)\n",
    "predictions = rfModel.transform(test_dataset)\n",
    "predictions = labelConverter.transform(predictions) # Transform labels\n",
    "\n",
    "predictions.filter(predictions['prediction'] == 0) \\\n",
    "    .select(\"text\",\"probability\",\"review_score\",\"predictedScore\") \\\n",
    "    .orderBy(\"probability\", ascending=False) \\\n",
    "    .show(n = 15, truncate = 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Crossvalidation </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(labelCol=\"label\", \\\n",
    "                            featuresCol=\"features\", \\\n",
    "                            numTrees = 100, \\\n",
    "                            maxDepth = 4)\n",
    "\n",
    "# Create ParamGrid for Cross Validation\n",
    "paramGrid = (ParamGridBuilder()\n",
    "             .addGrid(rf.numTrees, [100, 200, 500]) # regularization parameter\n",
    "             .addGrid(rf.maxDepth, [4, 10, 20]) # Elastic Net Parameter (Ridge = 0)\n",
    "#            .addGrid(model.maxIter, [10, 20, 50]) #Number of iterations\n",
    "#            .addGrid(idf.numFeatures, [10, 100, 1000]) # Number of features\n",
    "             .build())\n",
    "\n",
    "# Create 5-fold CrossValidator\n",
    "cv = CrossValidator(estimator=rf, \\\n",
    "                    estimatorParamMaps=paramGrid, \\\n",
    "                    evaluator=evaluator, \\\n",
    "                    numFolds=5)\n",
    "\n",
    "cvModel = cv.fit(dataset)\n",
    "\n",
    "predictions = cvModel.transform(test_dataset)\n",
    "predictions = labelConverter.transform(predictions) # Transform labels\n",
    "\n",
    "# Evaluate best model\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\", labelCol=\"label\")\n",
    "evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = cvModel.bestModel\n",
    "best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_numTrees = best_model.getNumTrees\n",
    "best_maxDepth = best_model.getOrDefault('maxDepth')\n",
    "print(best_numTrees);print(best_maxDepth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.filter(predictions['prediction'] == 0) \\\n",
    "    .select(\"text\",\"probability\",\"review_score\",\"predictedScore\") \\\n",
    "    .orderBy(\"probability\", ascending=False) \\\n",
    "    .show(n = 15, truncate = 40)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "predictions.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>TF-IDF Features</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import HashingTF, IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "hashingTF = HashingTF(inputCol=\"filtered\", outputCol=\"rawFeatures\", numFeatures=20000)\n",
    "idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\", minDocFreq=5) #minDocFreq: remove sparse terms\n",
    "\n",
    "pipeline_tfidf = Pipeline(stages=[regexTokenizer, stopwordsRemover, hashingTF, idf, label_stringIdx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------------------+--------------------+--------------------+--------------------+--------------------+-----+\n",
      "|review_score|                text|               words|            filtered|         rawFeatures|            features|label|\n",
      "+------------+--------------------+--------------------+--------------------+--------------------+--------------------+-----+\n",
      "|           1|*Eye roll* I firs...|[eye, roll, i, fi...|[eye, roll, first...|(20000,[456,1305,...|(20000,[456,1305,...|  4.0|\n",
      "+------------+--------------------+--------------------+--------------------+--------------------+--------------------+-----+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# applying pipeline to training data\n",
    "pipelineFit_tfidf = pipeline_tfidf.fit(trainingData)\n",
    "dataset_tfidf = pipelineFit_tfidf.transform(trainingData)\n",
    "dataset_tfidf.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------------------+--------------------+--------------------+--------------------+--------------------+-----+\n",
      "|review_score|                text|               words|            filtered|         rawFeatures|            features|label|\n",
      "+------------+--------------------+--------------------+--------------------+--------------------+--------------------+-----+\n",
      "|           1|A waste of money ...|[a, waste, of, mo...|[waste, money, ti...|(20000,[437,450,1...|(20000,[437,450,1...|  4.0|\n",
      "+------------+--------------------+--------------------+--------------------+--------------------+--------------------+-----+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# applying pipeline to test data\n",
    "test_dataset_tfidf = pipelineFit_tfidf.transform(testData)\n",
    "test_dataset_tfidf.show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Logistic regression TF-IDF</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------------+----------------------------------------+------------+--------------+\n",
      "|                                    text|                             probability|review_score|predictedScore|\n",
      "+----------------------------------------+----------------------------------------+------------+--------------+\n",
      "|Beautifully done and down to earth I ...|[1.0,1.0951071313748669E-16,5.0335173...|           5|             5|\n",
      "|SO Twisty Twisted “I want my kids to ...|[1.0,6.689446406497144E-17,2.61317220...|           5|             5|\n",
      "|Engrossing story! During the first pa...|[1.0,3.252631500218192E-17,7.17720871...|           5|             5|\n",
      "|SLOW BUILD TO THE TOP OF THE ROLLER C...|[1.0,3.044315421944498E-17,3.72133604...|           5|             5|\n",
      "|On the edge of my seat The author rea...|[1.0,2.4405740959251534E-17,2.8124606...|           5|             5|\n",
      "|Great book! This has been the best bo...|[1.0,1.6857201275336582E-17,4.7220161...|           5|             5|\n",
      "|Can I Give It 10 Stars? What an amazi...|[1.0,1.2134401333156454E-17,1.3185953...|           5|             5|\n",
      "|King at his absolute best. This book ...|[1.0,8.731671491790918E-18,1.16207237...|           5|             5|\n",
      "|Another amazing Black Dagger Brotherh...|[1.0,6.608692984950224E-18,4.17227784...|           5|             5|\n",
      "|A Must Read This is one of the best b...|[1.0,4.164189697349588E-18,4.47423826...|           5|             5|\n",
      "|An Elegant Read - Highly recommended ...|[1.0,3.589723878756446E-18,1.41322591...|           5|             5|\n",
      "|Choose Your Own Adventure! This book ...|[1.0,1.7412393227994232E-18,8.7725755...|           5|             5|\n",
      "|Excellent book This was a well writte...|[1.0,1.6684852576570633E-18,1.2580050...|           5|             5|\n",
      "|I couldn't put it down! Talk about a ...|[1.0,1.5716867169963069E-18,2.2419950...|           5|             5|\n",
      "|Gripping, Consuming This book, with S...|[1.0,1.3784849694631732E-18,7.1969513...|           5|             5|\n",
      "+----------------------------------------+----------------------------------------+------------+--------------+\n",
      "only showing top 15 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr_tfidf = LogisticRegression(maxIter=20, regParam=0, elasticNetParam=0)\n",
    "\n",
    "lrModel_tfidf = lr_tfidf.fit(dataset_tfidf)\n",
    "predictions_tfidf = lrModel_tfidf.transform(test_dataset_tfidf)\n",
    "predictions_tfidf = labelConverter.transform(predictions_tfidf) # Transform labels\n",
    "\n",
    "predictions_tfidf.filter(predictions_tfidf['prediction'] == 0) \\\n",
    "    .select(\"text\",\"probability\",\"review_score\",\"predictedScore\") \\\n",
    "    .orderBy(\"probability\", ascending=False) \\\n",
    "    .show(n = 15, truncate = 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7240072934143862"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator_tfidf = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "evaluator_tfidf.evaluate(predictions_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(review_score=1, text='A waste of money and time Too long... too overly dramatic.  Narrator on audio needs to tone it down down down a few notches. Like waiting for paint to dry.', words=['a', 'waste', 'of', 'money', 'and', 'time', 'too', 'long', 'too', 'overly', 'dramatic', 'narrator', 'on', 'audio', 'needs', 'to', 'tone', 'it', 'down', 'down', 'down', 'a', 'few', 'notches', 'like', 'waiting', 'for', 'paint', 'to', 'dry'], filtered=['waste', 'money', 'time', 'long', 'overly', 'dramatic', 'narrator', 'audio', 'needs', 'tone', 'notches', 'like', 'waiting', 'paint', 'dry'], rawFeatures=SparseVector(20000, {437: 1.0, 450: 1.0, 1933: 1.0, 3330: 1.0, 4511: 1.0, 5242: 1.0, 8904: 1.0, 12378: 1.0, 15666: 1.0, 15866: 1.0, 16256: 1.0, 16270: 1.0, 16303: 1.0, 18157: 1.0, 19556: 1.0}), features=SparseVector(20000, {437: 5.547, 450: 4.3507, 1933: 5.9147, 3330: 1.7335, 4511: 4.8538, 5242: 4.1607, 8904: 2.6826, 12378: 5.547, 15666: 3.9688, 15866: 4.6462, 16256: 5.1675, 16270: 0.0, 16303: 0.0, 18157: 1.8222, 19556: 4.5284}), label=4.0, rawPrediction=DenseVector([-2.2326, -3.9938, -2.9213, 6.856, 2.2917]), probability=DenseVector([0.0001, 0.0, 0.0001, 0.9895, 0.0103]), prediction=3.0, predictedScore='2')]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_tfidf.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Cross-validation</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_tfidf = LogisticRegression(maxIter=20, regParam=0, elasticNetParam=0)\n",
    "\n",
    "# Create ParamGrid for Cross Validation\n",
    "paramGrid = (ParamGridBuilder()\n",
    "             .addGrid(lr_tfidf.regParam, [0.01, 0.05, 0.1, 0.2, 0.3, 0.5]) # regularization parameter\n",
    "             .addGrid(lr_tfidf.elasticNetParam, [0.0, 0.2, 0.4, 0.6, 0.8, 1]) # Elastic Net Parameter (Ridge = 0)\n",
    "#            .addGrid(model.maxIter, [10, 20, 50]) #Number of iterations\n",
    "#            .addGrid(idf.numFeatures, [10, 100, 1000]) # Number of features\n",
    "             .build())\n",
    "\n",
    "# Create 5-fold CrossValidator\n",
    "cv_tfidf = CrossValidator(estimator=lr_tfidf, \\\n",
    "                    estimatorParamMaps=paramGrid, \\\n",
    "                    evaluator=evaluator, \\\n",
    "                    numFolds=5)\n",
    "\n",
    "cvModel_tfidf = cv_tfidf.fit(dataset_tfidf)\n",
    "\n",
    "predictions_tfidf = cvModel_tfidf.transform(test_dataset_tfidf)\n",
    "predictions_tfidf = labelConverter.transform(predictions_tfidf) # Transform labels\n",
    "\n",
    "# Evaluate best model\n",
    "evaluator_tfidf = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "evaluator_tfidf.evaluate(predictions_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_tfidf = cvModel_tfidf.bestModel\n",
    "best_model_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_reg_param_tfidf = best_model_tfidf._java_obj.getRegParam()\n",
    "best_elasticnet_param_tfidf = best_model_tfidf._java_obj.getElasticNetParam()\n",
    "print(best_reg_param_tfidf);print(best_elasticnet_param_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_tfidf.filter(predictions_tfidf['prediction'] == 0) \\\n",
    "    .select(\"text\",\"probability\",\"review_score\",\"predictedScore\") \\\n",
    "    .orderBy(\"probability\", ascending=False) \\\n",
    "    .show(n = 15, truncate = 40)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "predictions_tfidf.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Naive Bayes TF-IDF</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nb_tfidf = NaiveBayes(smoothing=1)\n",
    "\n",
    "model_tfidf = nb_tfidf.fit(dataset_tfidf)\n",
    "predictions_tfidf = model_tfidf.transform(test_dataset_tfidf)\n",
    "predictions_tfidf = labelConverter.transform(predictions_tfidf) # Transform labels\n",
    "\n",
    "predictions_tfidf.filter(predictions_tfidf['prediction'] == 0) \\\n",
    "    .select(\"text\",\"probability\",\"review_score\",\"predictedScore\") \\\n",
    "    .orderBy(\"probability\", ascending=False) \\\n",
    "    .show(n = 15, truncate = 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "evaluator_tfidf = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "evaluator_tfidf.evaluate(predictions_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Random Forest TF-IDF</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "\n",
    "rf_tfidf = RandomForestClassifier(labelCol=\"label\", \\\n",
    "                            featuresCol=\"features\", \\\n",
    "                            numTrees = 100, \\\n",
    "                            maxDepth = 4, \\\n",
    "                            maxBins = 32)\n",
    "\n",
    "# Train model with Training Data\n",
    "rfModel_tfidf = rf_tfidf.fit(dataset_tfidf)\n",
    "predictions_tfidf = rfModel_tfidf.transform(test_dataset_tfidf)\n",
    "predictions_tfidf = labelConverter.transform(predictions_tfidf) # Transform labels\n",
    "\n",
    "predictions_tfidf.filter(predictions_tfidf['prediction'] == 0) \\\n",
    "    .select(\"text\",\"probability\",\"review_score\",\"predictedScore\") \\\n",
    "    .orderBy(\"probability\", ascending=False) \\\n",
    "    .show(n = 15, truncate = 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator_tfidf = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "evaluator_tfidf.evaluate(predictions_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Crossvalidation </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "\n",
    "rf_tfidf = RandomForestClassifier(labelCol=\"label\", \\\n",
    "                            featuresCol=\"features\", \\\n",
    "                            numTrees = 100, \\\n",
    "                            maxDepth = 4)\n",
    "\n",
    "# Create ParamGrid for Cross Validation\n",
    "paramGrid = (ParamGridBuilder()\n",
    "             .addGrid(rf_tfidf.numTrees, [100, 200, 500]) # regularization parameter\n",
    "             .addGrid(rf_tfidf.maxDepth, [4, 10, 20]) # Elastic Net Parameter (Ridge = 0)\n",
    "#            .addGrid(model.maxIter, [10, 20, 50]) #Number of iterations\n",
    "#            .addGrid(idf.numFeatures, [10, 100, 1000]) # Number of features\n",
    "             .build())\n",
    "\n",
    "# Create 5-fold CrossValidator\n",
    "cv_tfidf = CrossValidator(estimator=rf_tfidf, \\\n",
    "                    estimatorParamMaps=paramGrid, \\\n",
    "                    evaluator=evaluator, \\\n",
    "                    numFolds=5)\n",
    "\n",
    "cvModel_tfidf = cv_tfidf.fit(dataset_tfidf)\n",
    "\n",
    "predictions_tfidf = cvModel_tfidf.transform(test_dataset_tfidf)\n",
    "predictions_tfidf = labelConverter.transform(predictions_tfidf) # Transform labels\n",
    "\n",
    "# Evaluate best model\n",
    "evaluator_tfidf = MulticlassClassificationEvaluator(predictionCol=\"prediction\", labelCol=\"label\")\n",
    "evaluator_tfidf.evaluate(predictions_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_tfidf = cvModel_tfidf.bestModel\n",
    "best_model_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_numTrees_tfidf = best_model_tfidf.getNumTrees\n",
    "best_maxDepth_tfidf = best_model_tfidf.getOrDefault('maxDepth')\n",
    "print(best_numTrees_tfidf);print(best_maxDepth_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_tfidf.filter(predictions_tfidf['prediction'] == 0) \\\n",
    "    .select(\"text\",\"probability\",\"review_score\",\"predictedScore\") \\\n",
    "    .orderBy(\"probability\", ascending=False) \\\n",
    "    .show(n = 15, truncate = 40)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "predictions_tfidf.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Word2Vec </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Word2Vec\n",
    "\n",
    "w2v = Word2Vec(vectorSize=3, minCount=0, inputCol=\"filtered\", outputCol=\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_w2v = Pipeline(stages=[regexTokenizer, stopwordsRemover, w2v, label_stringIdx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# applying pipeline to training data\n",
    "pipelineFit_w2v = pipeline_w2v.fit(trainingData)\n",
    "dataset_w2v = pipelineFit_w2v.transform(trainingData)\n",
    "dataset_w2v.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# applying pipeline to test data\n",
    "test_dataset_w2v = pipelineFit_w2v.transform(testData)\n",
    "test_dataset_w2v.show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Logistic regression Word2Vec</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_w2v = LogisticRegression(maxIter=20, regParam=0, elasticNetParam=0)\n",
    "\n",
    "lrModel_w2v = lr_w2v.fit(dataset_w2v)\n",
    "predictions_w2v = lrModel_w2v.transform(test_dataset_w2v)\n",
    "predictions_w2v = labelConverter.transform(predictions_w2v) # Transform labels\n",
    "\n",
    "predictions_w2v.filter(predictions_w2v['prediction'] == 0) \\\n",
    "    .select(\"text\",\"probability\",\"review_score\",\"predictedScore\") \\\n",
    "    .orderBy(\"probability\", ascending=False) \\\n",
    "    .show(n = 15, truncate = 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predictions_w2v.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator_w2v = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "evaluator_w2v.evaluate(predictions_w2v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Cross-validation</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_w2v = LogisticRegression(maxIter=20, regParam=0, elasticNetParam=0)\n",
    "\n",
    "# Create ParamGrid for Cross Validation\n",
    "paramGrid = (ParamGridBuilder()\n",
    "             .addGrid(lr_w2v.regParam, [0.01, 0.05, 0.1, 0.2, 0.3, 0.5]) # regularization parameter\n",
    "             .addGrid(lr_w2v.elasticNetParam, [0.0, 0.2, 0.4, 0.6, 0.8, 1]) # Elastic Net Parameter (Ridge = 0)\n",
    "#            .addGrid(model.maxIter, [10, 20, 50]) #Number of iterations\n",
    "#            .addGrid(idf.numFeatures, [10, 100, 1000]) # Number of features\n",
    "             .build())\n",
    "\n",
    "# Create 5-fold CrossValidator\n",
    "cv_w2v = CrossValidator(estimator=lr_w2v, \\\n",
    "                    estimatorParamMaps=paramGrid, \\\n",
    "                    evaluator=evaluator, \\\n",
    "                    numFolds=5)\n",
    "\n",
    "cvModel_w2v = cv_w2v.fit(dataset_w2v)\n",
    "\n",
    "predictions_w2v = cvModel_w2v.transform(test_dataset_w2v)\n",
    "predictions_w2v = labelConverter.transform(predictions_w2v) # Transform labels\n",
    "\n",
    "# Evaluate best model\n",
    "evaluator_w2v = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "evaluator_w2v.evaluate(predictions_w2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_w2v = cvModel_w2v.bestModel\n",
    "best_model_w2v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_reg_param_w2v = best_model_w2v._java_obj.getRegParam()\n",
    "best_elasticnet_param_w2v = best_model_w2v._java_obj.getElasticNetParam()\n",
    "print(best_reg_param_w2v);print(best_elasticnet_param_w2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_w2v.filter(predictions_w2v['prediction'] == 0) \\\n",
    "    .select(\"text\",\"probability\",\"review_score\",\"predictedScore\") \\\n",
    "    .orderBy(\"probability\", ascending=False) \\\n",
    "    .show(n = 15, truncate = 40)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "predictions_w2v.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Naive Bayes Word2Vec</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nb_w2v = NaiveBayes(smoothing=1)\n",
    "\n",
    "model_w2v = nb_w2v.fit(dataset_w2v)\n",
    "predictions_w2v = model_w2v.transform(test_dataset_w2v)\n",
    "predictions_w2v = labelConverter.transform(predictions_w2v) # Transform labels\n",
    "\n",
    "predictions_w2v.filter(predictions_w2v['prediction'] == 0) \\\n",
    "    .select(\"text\",\"probability\",\"review_score\",\"predictedScore\") \\\n",
    "    .orderBy(\"probability\", ascending=False) \\\n",
    "    .show(n = 15, truncate = 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "evaluator_w2v = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "evaluator_w2v.evaluate(predictions_w2v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Random Forest Word2Vec</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_w2v = RandomForestClassifier(labelCol=\"label\", \\\n",
    "                            featuresCol=\"features\", \\\n",
    "                            numTrees = 100, \\\n",
    "                            maxDepth = 4, \\\n",
    "                            maxBins = 32)\n",
    "\n",
    "# Train model with Training Data\n",
    "rfModel_w2v = rf_w2v.fit(dataset_w2v)\n",
    "predictions_w2v = rfModel_w2v.transform(test_dataset_w2v)\n",
    "predictions_w2v = labelConverter.transform(predictions_w2v) # Transform labels\n",
    "\n",
    "predictions_w2v.filter(predictions_w2v['prediction'] == 0) \\\n",
    "    .select(\"text\",\"probability\",\"review_score\",\"predictedScore\") \\\n",
    "    .orderBy(\"probability\", ascending=False) \\\n",
    "    .show(n = 15, truncate = 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator_w2v = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "evaluator_w2v.evaluate(predictions_w2v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Crossvalidation </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_w2v = RandomForestClassifier(labelCol=\"label\", \\\n",
    "                            featuresCol=\"features\", \\\n",
    "                            numTrees = 100, \\\n",
    "                            maxDepth = 4)\n",
    "\n",
    "# Create ParamGrid for Cross Validation\n",
    "paramGrid = (ParamGridBuilder()\n",
    "             .addGrid(rf_w2v.numTrees, [100, 200, 500]) # regularization parameter\n",
    "             .addGrid(rf_w2v.maxDepth, [4, 10, 20]) # Elastic Net Parameter (Ridge = 0)\n",
    "#            .addGrid(model.maxIter, [10, 20, 50]) #Number of iterations\n",
    "#            .addGrid(idf.numFeatures, [10, 100, 1000]) # Number of features\n",
    "             .build())\n",
    "\n",
    "# Create 5-fold CrossValidator\n",
    "cv_w2v = CrossValidator(estimator=rf_w2v, \\\n",
    "                    estimatorParamMaps=paramGrid, \\\n",
    "                    evaluator=evaluator, \\\n",
    "                    numFolds=5)\n",
    "\n",
    "cvModel_w2v = cv_w2v.fit(dataset_w2v)\n",
    "\n",
    "predictions_w2v = cvModel_w2v.transform(test_dataset_w2v)\n",
    "predictions_w2v = labelConverter.transform(predictions_w2v) # Transform labels\n",
    "\n",
    "# Evaluate best model\n",
    "evaluator_w2v = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "evaluator_w2v.evaluate(predictions_w2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_w2v = cvModel_w2v.bestModel\n",
    "best_model_w2v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_numTrees_w2v = best_model_w2v.getNumTrees\n",
    "best_maxDepth_w2v = best_model_w2v.getOrDefault('maxDepth')\n",
    "print(best_numTrees_w2v);print(best_maxDepth_w2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_w2v.filter(predictions_w2v['prediction'] == 0) \\\n",
    "    .select(\"text\",\"probability\",\"review_score\",\"predictedScore\") \\\n",
    "    .orderBy(\"probability\", ascending=False) \\\n",
    "    .show(n = 15, truncate = 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_w2v.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 122.66666599999999,
   "position": {
    "height": "144px",
    "left": "1009px",
    "right": "20px",
    "top": "120px",
    "width": "250px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "block",
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
